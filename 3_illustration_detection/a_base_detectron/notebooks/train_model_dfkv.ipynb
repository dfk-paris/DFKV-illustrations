{"cells":[{"cell_type":"markdown","metadata":{"id":"UVva9HAJGhLG"},"source":["# This notebook trains a visual content recognition model on modified *Beyond Words* and DFKV bounding box annotations. \n","\n","\n","This notebook finetunes a pre-trained object detection model (Faster-RCNN R50-FPN) to predict bounding boxes around illustrations in historical newspapers, journals and books images. \n","\n","This notebook is based on the following notebook:\n","\n","- https://colab.research.google.com/drive/16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5\n","\n","and on the work of :\n","\n","*Benjamin Charles Germain Lee*\n","(LOC Innovator-in-Residence)\n","\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"vB1hB7N5nr6_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1647422477390,"user_tz":-60,"elapsed":12645,"user":{"displayName":"Elisa Michelet","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17163883302948708095"}},"outputId":"ba07ba73-732b-4d3e-f471-aef689a8cf61"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/facebookresearch/detectron2.git\n","  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-d3l1tj27\n","  Running command git clone -q https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-d3l1tj27\n","Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (7.1.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (3.2.2)\n","Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (2.0.4)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.1.0)\n","Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.1.8)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.8.9)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.3.0)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (4.63.0)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (2.8.0)\n","Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.1.5.post20220305)\n","Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.1.9)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (0.16.0)\n","Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.3.0)\n","Requirement already satisfied: omegaconf>=2.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (2.1.1)\n","Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.1.1)\n","Requirement already satisfied: black==21.4b2 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (21.4b2)\n","Requirement already satisfied: scipy>1.5.1 in /usr/local/lib/python3.7/dist-packages (from detectron2==0.6) (1.7.3)\n","Requirement already satisfied: click>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (7.1.2)\n","Requirement already satisfied: pathspec<1,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (0.9.0)\n","Requirement already satisfied: toml>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (0.10.2)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (3.10.0.2)\n","Requirement already satisfied: typed-ast>=1.4.2 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (1.5.2)\n","Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (1.4.4)\n","Requirement already satisfied: regex>=2020.1.8 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (2022.3.15)\n","Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.7/dist-packages (from black==21.4b2->detectron2==0.6) (0.4.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.21.5)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2==0.6) (5.4.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.8 in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.1->detectron2==0.6) (4.8)\n","Requirement already satisfied: portalocker in /usr/local/lib/python3.7/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (2.4.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (3.0.7)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->detectron2==0.6) (1.3.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->detectron2==0.6) (1.15.0)\n","Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources->hydra-core>=1.1->detectron2==0.6) (3.7.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.35.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.0.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.37.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.8.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.44.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (2.23.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (3.3.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (57.4.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (0.4.6)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->detectron2==0.6) (3.17.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.2.8)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.2.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->detectron2==0.6) (4.11.2)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.10)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->detectron2==0.6) (3.2.0)\n"]}],"source":["!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1647422477390,"user":{"displayName":"Elisa Michelet","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17163883302948708095"},"user_tz":-60},"id":"HkjfZYZZthhw"},"outputs":[],"source":["#!git clone https://github.com/facebookresearch/detectron2.git"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2756,"status":"ok","timestamp":1647422480139,"user":{"displayName":"Elisa Michelet","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17163883302948708095"},"user_tz":-60},"id":"kdIO4wEno3xv","outputId":"09009664-4617-484f-e27b-c4b9a0f43ed4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/gdrive', force_remount=True)"]},{"cell_type":"code","source":["%cd gdrive/My Drive/newspaper-navigator/newspaper-navigator/notebooks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qy42mcMAkq0x","executionInfo":{"status":"ok","timestamp":1647422480140,"user_tz":-60,"elapsed":11,"user":{"displayName":"Elisa Michelet","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17163883302948708095"}},"outputId":"753f704a-104d-4cfb-a98e-686999f0b643"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/newspaper-navigator/newspaper-navigator/notebooks\n"]}]},{"cell_type":"markdown","metadata":{"id":"jg6ej72sF1Yr"},"source":["# First, we handle imports and data formatting.\n","\n","This cell imports libraries and constructs a COCO instance using the training and validation JSON files; essentially, this enables the model to handle the data loading using the COCO standard:"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1413,"status":"ok","timestamp":1647422481545,"user":{"displayName":"Elisa Michelet","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17163883302948708095"},"user_tz":-60},"id":"SvlYES5tGrU4"},"outputs":[],"source":["# to display images inline\n","%matplotlib inline\n","\n","# import some common libraries\n","import cv2\n","import random\n","import glob\n","import os\n","import shutil\n","import json\n","import math\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# import detectron2, etc.\n","import detectron2\n","from detectron2.config import get_cfg\n","from detectron2.data import DatasetCatalog, MetadataCatalog\n","from detectron2.data.datasets import register_coco_instances\n","from detectron2.engine import DefaultTrainer\n","from detectron2.engine import DefaultPredictor\n","from detectron2.evaluation import COCOEvaluator\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.utils.visualizer import ColorMode\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# cd into the beyond words dataset\n","os.chdir(\"../beyond_words_data\")\n","\n","# we now register the dataset\n","register_coco_instances(\"beyond_words_train\", {}, \"train_annos.json\", \"images\")\n","register_coco_instances(\"beyond_words_val\", {}, \"test_annos.json\", \"images\")\n","register_coco_instances(\"beyond_words_combined\", {}, \"anno_complete.json\", \"images\")"]},{"cell_type":"markdown","metadata":{"id":"ZoRMNY_bWJ2_"},"source":["# Next, we visualize some examples.\n","\n","This cell visualizes some examples from the training set:"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1FC0n52zok6NENmWg_jPyUJZvsP8PuIaO"},"executionInfo":{"elapsed":5475,"status":"ok","timestamp":1647422487018,"user":{"displayName":"Elisa Michelet","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17163883302948708095"},"user_tz":-60},"id":"Fc_ElhymV8Ik","outputId":"d5a8509f-b641-4b1a-b1a3-ad1d543d2c90"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# sets random seed for reproducibility\n","random.seed(42)\n","\n","dataset_dicts = DatasetCatalog.get(\"beyond_words_train\")\n","my_metadata = MetadataCatalog.get(\"beyond_words_val\")\n","\n","n_examples_to_display = 5\n","for d in random.sample(dataset_dicts, n_examples_to_display):\n","    print(d[\"file_name\"])\n","    img = cv2.imread(d[\"file_name\"])\n","    visualizer = Visualizer(img[:, :, ::-1], metadata=my_metadata, scale=0.5)\n","    v = visualizer.draw_dataset_dict(d)\n","    plt.figure(figsize=(15,12))\n","    plt.imshow(v.get_image()[:, :, ::-1])\n"]},{"cell_type":"markdown","metadata":{"id":"R-FOkvMlWvlI"},"source":["# Next, we finetune the Faster-RCNN implementation from Detectron2's Model Zoo.\n","\n","We can pick our choice of pre-trained model here: https://github.com/facebookresearch/detectron2/blob/master/MODEL_ZOO.md#coco-object-detection-baselines.\n","\n","The 7 classes of visual content are:\n","\n","- Photograph\n","- Illustration\n","- Map\n","- Comics/Cartoon\n","- Editorial Cartoon\n","- Headline\n","- Advertisement\n","\n","Below, we finetune \"Faster_rcnn_R_50_FPN_3x\" and evaluate mean average precision on the held-out data (80%-20% train-val split); for this demo we run for 10 epochs - feel free to run for more epochs and watch the performance on the validation set improve!\n","\n","Note that there are lines of code below (currently commented out) for saving intermediate model weights and predictions on the validation set to an S3 bucket for later analysis.\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"13EbVOPpxw76","executionInfo":{"status":"ok","timestamp":1647422487019,"user_tz":-60,"elapsed":4,"user":{"displayName":"Elisa Michelet","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17163883302948708095"}}},"outputs":[],"source":["# sets batch size\n","batch_size = 16\n","# sets epoch size accordingly (to convert iterations to epochs)\n","epoch = math.ceil(2748/float(batch_size))\n","# sets total number of epochs to train for\n","epoch_num = 10\n","\n","cfg = get_cfg()\n","# loads in correct pre-trained model parameters\n","cfg.merge_from_file(\"../..//detectron2/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n","# loads pre-trained model weights (from Model Zoo)\n","cfg.MODEL.WEIGHTS = \"detectron2://COCO-Detection/faster_rcnn_R_50_FPN_3x/137849458/model_final_280758.pkl\"\n","# loads in training/val data using the registered COCO instance\n","cfg.DATASETS.TRAIN = (\"beyond_words_train\",)\n","cfg.DATASETS.TEST = (\"beyond_words_val\",)\n","# sets number of object classes\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n","\n","# makes output directory for weights, etc.\n","os.makedirs(\"../model_weights/\", exist_ok=True)\n","\n","# sets output directory for model weights, checkpoints, etc.\n","cfg.OUTPUT_DIR = '../model_weights/'\n","\n","# some hyperparameters\n","cfg.SOLVER.BASE_LR = 0.00025\n","cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 64\n","cfg.SOLVER.MAX_ITER = epoch\n","cfg.DATALOADER.NUM_WORKERS = 2\n","cfg.SOLVER.IMS_PER_BATCH = 8"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IyLDoZ8iVVZv","scrolled":true,"outputId":"f7a30d42-4663-4e12-80eb-9ff0807d18f2","executionInfo":{"status":"ok","timestamp":1647422117543,"user_tz":-60,"elapsed":1705978,"user":{"displayName":"Elisa Michelet","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17163883302948708095"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["EPOCH 1\n","\u001b[32m[03/16 08:46:58 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n","    )\n","  )\n",")\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:46:58 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 08:46:58 d2.data.datasets.coco]: \u001b[0mLoaded 2575 images in COCO format from train_annos.json\n","\u001b[32m[03/16 08:46:58 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 2575 images left.\n","\u001b[32m[03/16 08:46:58 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n","\u001b[36m|   category   | #instances   |\n","|:------------:|:-------------|\n","| Illustration | 4842         |\n","|              |              |\u001b[0m\n","\u001b[32m[03/16 08:46:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","\u001b[32m[03/16 08:46:58 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[32m[03/16 08:46:58 d2.data.common]: \u001b[0mSerializing 2575 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 08:46:58 d2.data.common]: \u001b[0mSerialized dataset takes 0.65 MiB\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:46:58 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n","\u001b[32m[03/16 08:47:08 d2.engine.hooks]: \u001b[0mLoading scheduler from state_dict ...\n","\u001b[32m[03/16 08:47:08 d2.engine.train_loop]: \u001b[0mStarting training from iteration 1376\n","\u001b[32m[03/16 08:47:08 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:00 (0:00:00 on hooks)\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:47:08 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 08:47:08 d2.data.datasets.coco]: \u001b[0mLoaded 644 images in COCO format from test_annos.json\n","\u001b[32m[03/16 08:47:08 d2.data.build]: \u001b[0mDistribution of instances among all 1 categories:\n","\u001b[36m|   category   | #instances   |\n","|:------------:|:-------------|\n","| Illustration | 1216         |\n","|              |              |\u001b[0m\n","\u001b[32m[03/16 08:47:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[03/16 08:47:08 d2.data.common]: \u001b[0mSerializing 644 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 08:47:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.16 MiB\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:47:08 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n","\u001b[32m[03/16 08:47:08 d2.utils.events]: \u001b[0m iter: 1377    lr: N/A  max_mem: 322M\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:47:08 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:47:08 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 08:47:08 d2.data.datasets.coco]: \u001b[0mLoaded 644 images in COCO format from test_annos.json\n","\u001b[32m[03/16 08:47:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[03/16 08:47:08 d2.data.common]: \u001b[0mSerializing 644 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 08:47:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.16 MiB\n","\u001b[32m[03/16 08:47:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 644 batches\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[32m[03/16 08:47:11 d2.evaluation.evaluator]: \u001b[0mInference done 11/644. Dataloading: 0.0482 s/iter. Inference: 0.0917 s/iter. Eval: 0.0002 s/iter. Total: 0.1402 s/iter. ETA=0:01:28\n","\u001b[32m[03/16 08:47:16 d2.evaluation.evaluator]: \u001b[0mInference done 44/644. Dataloading: 0.0582 s/iter. Inference: 0.0920 s/iter. Eval: 0.0002 s/iter. Total: 0.1505 s/iter. ETA=0:01:30\n","\u001b[32m[03/16 08:47:21 d2.evaluation.evaluator]: \u001b[0mInference done 76/644. Dataloading: 0.0606 s/iter. Inference: 0.0930 s/iter. Eval: 0.0002 s/iter. Total: 0.1542 s/iter. ETA=0:01:27\n","\u001b[32m[03/16 08:47:26 d2.evaluation.evaluator]: \u001b[0mInference done 107/644. Dataloading: 0.0630 s/iter. Inference: 0.0937 s/iter. Eval: 0.0002 s/iter. Total: 0.1572 s/iter. ETA=0:01:24\n","\u001b[32m[03/16 08:47:31 d2.evaluation.evaluator]: \u001b[0mInference done 139/644. Dataloading: 0.0627 s/iter. Inference: 0.0938 s/iter. Eval: 0.0002 s/iter. Total: 0.1570 s/iter. ETA=0:01:19\n","\u001b[32m[03/16 08:47:36 d2.evaluation.evaluator]: \u001b[0mInference done 172/644. Dataloading: 0.0616 s/iter. Inference: 0.0939 s/iter. Eval: 0.0002 s/iter. Total: 0.1559 s/iter. ETA=0:01:13\n","\u001b[32m[03/16 08:47:41 d2.evaluation.evaluator]: \u001b[0mInference done 207/644. Dataloading: 0.0595 s/iter. Inference: 0.0940 s/iter. Eval: 0.0002 s/iter. Total: 0.1539 s/iter. ETA=0:01:07\n","\u001b[32m[03/16 08:47:46 d2.evaluation.evaluator]: \u001b[0mInference done 239/644. Dataloading: 0.0602 s/iter. Inference: 0.0940 s/iter. Eval: 0.0002 s/iter. Total: 0.1546 s/iter. ETA=0:01:02\n","\u001b[32m[03/16 08:47:51 d2.evaluation.evaluator]: \u001b[0mInference done 271/644. Dataloading: 0.0604 s/iter. Inference: 0.0942 s/iter. Eval: 0.0002 s/iter. Total: 0.1550 s/iter. ETA=0:00:57\n","\u001b[32m[03/16 08:47:56 d2.evaluation.evaluator]: \u001b[0mInference done 306/644. Dataloading: 0.0594 s/iter. Inference: 0.0943 s/iter. Eval: 0.0002 s/iter. Total: 0.1541 s/iter. ETA=0:00:52\n","\u001b[32m[03/16 08:48:02 d2.evaluation.evaluator]: \u001b[0mInference done 340/644. Dataloading: 0.0588 s/iter. Inference: 0.0945 s/iter. Eval: 0.0002 s/iter. Total: 0.1537 s/iter. ETA=0:00:46\n","\u001b[32m[03/16 08:48:07 d2.evaluation.evaluator]: \u001b[0mInference done 374/644. Dataloading: 0.0582 s/iter. Inference: 0.0946 s/iter. Eval: 0.0002 s/iter. Total: 0.1533 s/iter. ETA=0:00:41\n","\u001b[32m[03/16 08:48:12 d2.evaluation.evaluator]: \u001b[0mInference done 409/644. Dataloading: 0.0572 s/iter. Inference: 0.0948 s/iter. Eval: 0.0002 s/iter. Total: 0.1524 s/iter. ETA=0:00:35\n","\u001b[32m[03/16 08:48:17 d2.evaluation.evaluator]: \u001b[0mInference done 445/644. Dataloading: 0.0559 s/iter. Inference: 0.0951 s/iter. Eval: 0.0002 s/iter. Total: 0.1513 s/iter. ETA=0:00:30\n","\u001b[32m[03/16 08:48:22 d2.evaluation.evaluator]: \u001b[0mInference done 480/644. Dataloading: 0.0553 s/iter. Inference: 0.0952 s/iter. Eval: 0.0002 s/iter. Total: 0.1508 s/iter. ETA=0:00:24\n","\u001b[32m[03/16 08:48:27 d2.evaluation.evaluator]: \u001b[0mInference done 515/644. Dataloading: 0.0550 s/iter. Inference: 0.0951 s/iter. Eval: 0.0002 s/iter. Total: 0.1504 s/iter. ETA=0:00:19\n","\u001b[32m[03/16 08:48:32 d2.evaluation.evaluator]: \u001b[0mInference done 549/644. Dataloading: 0.0548 s/iter. Inference: 0.0952 s/iter. Eval: 0.0002 s/iter. Total: 0.1504 s/iter. ETA=0:00:14\n","\u001b[32m[03/16 08:48:37 d2.evaluation.evaluator]: \u001b[0mInference done 574/644. Dataloading: 0.0570 s/iter. Inference: 0.0955 s/iter. Eval: 0.0002 s/iter. Total: 0.1529 s/iter. ETA=0:00:10\n","\u001b[32m[03/16 08:48:42 d2.evaluation.evaluator]: \u001b[0mInference done 594/644. Dataloading: 0.0604 s/iter. Inference: 0.0957 s/iter. Eval: 0.0002 s/iter. Total: 0.1565 s/iter. ETA=0:00:07\n","\u001b[32m[03/16 08:48:47 d2.evaluation.evaluator]: \u001b[0mInference done 615/644. Dataloading: 0.0631 s/iter. Inference: 0.0961 s/iter. Eval: 0.0002 s/iter. Total: 0.1595 s/iter. ETA=0:00:04\n","\u001b[32m[03/16 08:48:53 d2.evaluation.evaluator]: \u001b[0mInference done 640/644. Dataloading: 0.0647 s/iter. Inference: 0.0964 s/iter. Eval: 0.0002 s/iter. Total: 0.1615 s/iter. ETA=0:00:00\n","\u001b[32m[03/16 08:48:54 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:43.570564 (0.162082 s / iter per device, on 1 devices)\n","\u001b[32m[03/16 08:48:54 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:01 (0.096384 s / iter per device, on 1 devices)\n","\u001b[32m[03/16 08:48:54 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n","\u001b[32m[03/16 08:48:54 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ../model_weights/coco_instances_results.json\n","\u001b[32m[03/16 08:48:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n","Loading and preparing results...\n","DONE (t=0.01s)\n","creating index...\n","index created!\n","\u001b[32m[03/16 08:48:54 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n","\u001b[32m[03/16 08:48:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.07 seconds.\n","\u001b[32m[03/16 08:48:54 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n","\u001b[32m[03/16 08:48:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.624\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.800\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.715\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.448\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.400\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.764\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.802\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.795\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.802\n","\u001b[32m[03/16 08:48:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n","|:------:|:------:|:------:|:-----:|:------:|:------:|\n","| 62.409 | 80.032 | 71.545 |  nan  | 44.799 | 62.662 |\n","\u001b[32m[03/16 08:48:54 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n","\u001b[32m[03/16 08:48:54 d2.engine.defaults]: \u001b[0mEvaluation results for beyond_words_val in csv format:\n","\u001b[32m[03/16 08:48:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n","\u001b[32m[03/16 08:48:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n","\u001b[32m[03/16 08:48:54 d2.evaluation.testing]: \u001b[0mcopypaste: 62.4089,80.0319,71.5450,nan,44.7993,62.6622\n","EPOCH 2\n","\u001b[32m[03/16 08:48:55 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n","    )\n","  )\n",")\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:48:55 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 08:48:55 d2.data.datasets.coco]: \u001b[0mLoaded 2575 images in COCO format from train_annos.json\n","\u001b[32m[03/16 08:48:55 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 2575 images left.\n","\u001b[32m[03/16 08:48:55 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","\u001b[32m[03/16 08:48:55 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[32m[03/16 08:48:55 d2.data.common]: \u001b[0mSerializing 2575 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 08:48:55 d2.data.common]: \u001b[0mSerialized dataset takes 0.65 MiB\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:48:55 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n","\u001b[32m[03/16 08:48:56 d2.engine.hooks]: \u001b[0mLoading scheduler from state_dict ...\n","\u001b[32m[03/16 08:48:56 d2.engine.train_loop]: \u001b[0mStarting training from iteration 1376\n","\u001b[32m[03/16 08:48:56 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:00 (0:00:00 on hooks)\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:48:56 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 08:48:56 d2.data.datasets.coco]: \u001b[0mLoaded 644 images in COCO format from test_annos.json\n","\u001b[32m[03/16 08:48:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[03/16 08:48:56 d2.data.common]: \u001b[0mSerializing 644 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 08:48:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.16 MiB\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:48:56 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n","\u001b[32m[03/16 08:48:56 d2.utils.events]: \u001b[0m iter: 1377    lr: N/A  max_mem: 751M\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:48:56 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:48:56 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 08:48:56 d2.data.datasets.coco]: \u001b[0mLoaded 644 images in COCO format from test_annos.json\n","\u001b[32m[03/16 08:48:56 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[03/16 08:48:56 d2.data.common]: \u001b[0mSerializing 644 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 08:48:56 d2.data.common]: \u001b[0mSerialized dataset takes 0.16 MiB\n","\u001b[32m[03/16 08:48:56 d2.evaluation.evaluator]: \u001b[0mStart inference on 644 batches\n","\u001b[32m[03/16 08:48:58 d2.evaluation.evaluator]: \u001b[0mInference done 15/644. Dataloading: 0.0016 s/iter. Inference: 0.0975 s/iter. Eval: 0.0002 s/iter. Total: 0.0994 s/iter. ETA=0:01:02\n","\u001b[32m[03/16 08:49:03 d2.evaluation.evaluator]: \u001b[0mInference done 64/644. Dataloading: 0.0023 s/iter. Inference: 0.1000 s/iter. Eval: 0.0002 s/iter. Total: 0.1027 s/iter. ETA=0:00:59\n","\u001b[32m[03/16 08:49:08 d2.evaluation.evaluator]: \u001b[0mInference done 113/644. Dataloading: 0.0021 s/iter. Inference: 0.1006 s/iter. Eval: 0.0002 s/iter. Total: 0.1030 s/iter. ETA=0:00:54\n","\u001b[32m[03/16 08:49:13 d2.evaluation.evaluator]: \u001b[0mInference done 162/644. Dataloading: 0.0022 s/iter. Inference: 0.1009 s/iter. Eval: 0.0002 s/iter. Total: 0.1034 s/iter. ETA=0:00:49\n","\u001b[32m[03/16 08:49:18 d2.evaluation.evaluator]: \u001b[0mInference done 211/644. Dataloading: 0.0021 s/iter. Inference: 0.1010 s/iter. Eval: 0.0002 s/iter. Total: 0.1034 s/iter. ETA=0:00:44\n","\u001b[32m[03/16 08:49:23 d2.evaluation.evaluator]: \u001b[0mInference done 259/644. Dataloading: 0.0021 s/iter. Inference: 0.1012 s/iter. Eval: 0.0002 s/iter. Total: 0.1036 s/iter. ETA=0:00:39\n","\u001b[32m[03/16 08:49:28 d2.evaluation.evaluator]: \u001b[0mInference done 307/644. Dataloading: 0.0021 s/iter. Inference: 0.1014 s/iter. Eval: 0.0002 s/iter. Total: 0.1039 s/iter. ETA=0:00:35\n","\u001b[32m[03/16 08:49:33 d2.evaluation.evaluator]: \u001b[0mInference done 355/644. Dataloading: 0.0021 s/iter. Inference: 0.1015 s/iter. Eval: 0.0002 s/iter. Total: 0.1039 s/iter. ETA=0:00:30\n","\u001b[32m[03/16 08:49:38 d2.evaluation.evaluator]: \u001b[0mInference done 404/644. Dataloading: 0.0021 s/iter. Inference: 0.1015 s/iter. Eval: 0.0002 s/iter. Total: 0.1039 s/iter. ETA=0:00:24\n","\u001b[32m[03/16 08:49:43 d2.evaluation.evaluator]: \u001b[0mInference done 451/644. Dataloading: 0.0021 s/iter. Inference: 0.1019 s/iter. Eval: 0.0002 s/iter. Total: 0.1043 s/iter. ETA=0:00:20\n","\u001b[32m[03/16 08:49:48 d2.evaluation.evaluator]: \u001b[0mInference done 500/644. Dataloading: 0.0021 s/iter. Inference: 0.1018 s/iter. Eval: 0.0002 s/iter. Total: 0.1043 s/iter. ETA=0:00:15\n","\u001b[32m[03/16 08:49:53 d2.evaluation.evaluator]: \u001b[0mInference done 548/644. Dataloading: 0.0021 s/iter. Inference: 0.1019 s/iter. Eval: 0.0002 s/iter. Total: 0.1044 s/iter. ETA=0:00:10\n","\u001b[32m[03/16 08:49:59 d2.evaluation.evaluator]: \u001b[0mInference done 581/644. Dataloading: 0.0046 s/iter. Inference: 0.1026 s/iter. Eval: 0.0002 s/iter. Total: 0.1075 s/iter. ETA=0:00:06\n","\u001b[32m[03/16 08:50:04 d2.evaluation.evaluator]: \u001b[0mInference done 611/644. Dataloading: 0.0076 s/iter. Inference: 0.1032 s/iter. Eval: 0.0002 s/iter. Total: 0.1111 s/iter. ETA=0:00:03\n","\u001b[32m[03/16 08:50:09 d2.evaluation.evaluator]: \u001b[0mInference done 643/644. Dataloading: 0.0095 s/iter. Inference: 0.1037 s/iter. Eval: 0.0002 s/iter. Total: 0.1136 s/iter. ETA=0:00:00\n","\u001b[32m[03/16 08:50:09 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:12.647035 (0.113689 s / iter per device, on 1 devices)\n","\u001b[32m[03/16 08:50:09 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:06 (0.103690 s / iter per device, on 1 devices)\n","\u001b[32m[03/16 08:50:09 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n","\u001b[32m[03/16 08:50:09 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ../model_weights/coco_instances_results.json\n","\u001b[32m[03/16 08:50:09 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n","Loading and preparing results...\n","DONE (t=0.01s)\n","creating index...\n","index created!\n","\u001b[32m[03/16 08:50:09 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n","\u001b[32m[03/16 08:50:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.27 seconds.\n","\u001b[32m[03/16 08:50:10 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n","\u001b[32m[03/16 08:50:10 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.624\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.800\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.715\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.448\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.400\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.764\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.802\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.795\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.802\n","\u001b[32m[03/16 08:50:10 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n","|:------:|:------:|:------:|:-----:|:------:|:------:|\n","| 62.409 | 80.032 | 71.545 |  nan  | 44.799 | 62.662 |\n","\u001b[32m[03/16 08:50:10 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n","\u001b[32m[03/16 08:50:10 d2.engine.defaults]: \u001b[0mEvaluation results for beyond_words_val in csv format:\n","\u001b[32m[03/16 08:50:10 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n","\u001b[32m[03/16 08:50:10 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n","\u001b[32m[03/16 08:50:10 d2.evaluation.testing]: \u001b[0mcopypaste: 62.4089,80.0319,71.5450,nan,44.7993,62.6622\n","EPOCH 3\n","\u001b[32m[03/16 08:50:10 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n","    )\n","  )\n",")\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:50:10 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 08:50:10 d2.data.datasets.coco]: \u001b[0mLoaded 2575 images in COCO format from train_annos.json\n","\u001b[32m[03/16 08:50:10 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 2575 images left.\n","\u001b[32m[03/16 08:50:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","\u001b[32m[03/16 08:50:11 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[32m[03/16 08:50:11 d2.data.common]: \u001b[0mSerializing 2575 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 08:50:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.65 MiB\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:50:11 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n","\u001b[32m[03/16 08:50:11 d2.engine.hooks]: \u001b[0mLoading scheduler from state_dict ...\n","\u001b[32m[03/16 08:50:11 d2.engine.train_loop]: \u001b[0mStarting training from iteration 1376\n","\u001b[32m[03/16 08:50:11 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:00 (0:00:00 on hooks)\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:50:11 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 08:50:11 d2.data.datasets.coco]: \u001b[0mLoaded 644 images in COCO format from test_annos.json\n","\u001b[32m[03/16 08:50:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[03/16 08:50:11 d2.data.common]: \u001b[0mSerializing 644 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 08:50:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.16 MiB\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:50:11 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n","\u001b[32m[03/16 08:50:11 d2.utils.events]: \u001b[0m iter: 1377    lr: N/A  max_mem: 751M\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:50:11 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:50:11 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 08:50:11 d2.data.datasets.coco]: \u001b[0mLoaded 644 images in COCO format from test_annos.json\n","\u001b[32m[03/16 08:50:11 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[03/16 08:50:11 d2.data.common]: \u001b[0mSerializing 644 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 08:50:11 d2.data.common]: \u001b[0mSerialized dataset takes 0.16 MiB\n","\u001b[32m[03/16 08:50:11 d2.evaluation.evaluator]: \u001b[0mStart inference on 644 batches\n","\u001b[32m[03/16 08:50:14 d2.evaluation.evaluator]: \u001b[0mInference done 25/644. Dataloading: 0.0016 s/iter. Inference: 0.1015 s/iter. Eval: 0.0002 s/iter. Total: 0.1033 s/iter. ETA=0:01:03\n","\u001b[32m[03/16 08:50:19 d2.evaluation.evaluator]: \u001b[0mInference done 72/644. Dataloading: 0.0017 s/iter. Inference: 0.1036 s/iter. Eval: 0.0002 s/iter. Total: 0.1056 s/iter. ETA=0:01:00\n","\u001b[32m[03/16 08:50:24 d2.evaluation.evaluator]: \u001b[0mInference done 119/644. Dataloading: 0.0018 s/iter. Inference: 0.1038 s/iter. Eval: 0.0002 s/iter. Total: 0.1060 s/iter. ETA=0:00:55\n","\u001b[32m[03/16 08:50:29 d2.evaluation.evaluator]: \u001b[0mInference done 166/644. Dataloading: 0.0018 s/iter. Inference: 0.1041 s/iter. Eval: 0.0002 s/iter. Total: 0.1062 s/iter. ETA=0:00:50\n","\u001b[32m[03/16 08:50:34 d2.evaluation.evaluator]: \u001b[0mInference done 214/644. Dataloading: 0.0018 s/iter. Inference: 0.1041 s/iter. Eval: 0.0002 s/iter. Total: 0.1062 s/iter. ETA=0:00:45\n","\u001b[32m[03/16 08:50:39 d2.evaluation.evaluator]: \u001b[0mInference done 261/644. Dataloading: 0.0019 s/iter. Inference: 0.1043 s/iter. Eval: 0.0002 s/iter. Total: 0.1065 s/iter. ETA=0:00:40\n","\u001b[32m[03/16 08:50:44 d2.evaluation.evaluator]: \u001b[0mInference done 308/644. Dataloading: 0.0019 s/iter. Inference: 0.1044 s/iter. Eval: 0.0002 s/iter. Total: 0.1066 s/iter. ETA=0:00:35\n","\u001b[32m[03/16 08:50:50 d2.evaluation.evaluator]: \u001b[0mInference done 355/644. Dataloading: 0.0019 s/iter. Inference: 0.1046 s/iter. Eval: 0.0002 s/iter. Total: 0.1068 s/iter. ETA=0:00:30\n","\u001b[32m[03/16 08:50:55 d2.evaluation.evaluator]: \u001b[0mInference done 402/644. Dataloading: 0.0019 s/iter. Inference: 0.1046 s/iter. Eval: 0.0002 s/iter. Total: 0.1068 s/iter. ETA=0:00:25\n","\u001b[32m[03/16 08:51:00 d2.evaluation.evaluator]: \u001b[0mInference done 448/644. Dataloading: 0.0019 s/iter. Inference: 0.1049 s/iter. Eval: 0.0002 s/iter. Total: 0.1072 s/iter. ETA=0:00:21\n","\u001b[32m[03/16 08:51:05 d2.evaluation.evaluator]: \u001b[0mInference done 495/644. Dataloading: 0.0019 s/iter. Inference: 0.1049 s/iter. Eval: 0.0002 s/iter. Total: 0.1071 s/iter. ETA=0:00:15\n","\u001b[32m[03/16 08:51:10 d2.evaluation.evaluator]: \u001b[0mInference done 542/644. Dataloading: 0.0019 s/iter. Inference: 0.1050 s/iter. Eval: 0.0002 s/iter. Total: 0.1072 s/iter. ETA=0:00:10\n","\u001b[32m[03/16 08:51:15 d2.evaluation.evaluator]: \u001b[0mInference done 577/644. Dataloading: 0.0038 s/iter. Inference: 0.1054 s/iter. Eval: 0.0002 s/iter. Total: 0.1095 s/iter. ETA=0:00:07\n","\u001b[32m[03/16 08:51:20 d2.evaluation.evaluator]: \u001b[0mInference done 605/644. Dataloading: 0.0066 s/iter. Inference: 0.1059 s/iter. Eval: 0.0002 s/iter. Total: 0.1128 s/iter. ETA=0:00:04\n","\u001b[32m[03/16 08:51:25 d2.evaluation.evaluator]: \u001b[0mInference done 636/644. Dataloading: 0.0086 s/iter. Inference: 0.1064 s/iter. Eval: 0.0002 s/iter. Total: 0.1154 s/iter. ETA=0:00:00\n","\u001b[32m[03/16 08:51:26 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:14.218822 (0.116148 s / iter per device, on 1 devices)\n","\u001b[32m[03/16 08:51:26 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:08 (0.106453 s / iter per device, on 1 devices)\n","\u001b[32m[03/16 08:51:26 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n","\u001b[32m[03/16 08:51:26 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ../model_weights/coco_instances_results.json\n","\u001b[32m[03/16 08:51:26 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n","Loading and preparing results...\n","DONE (t=0.01s)\n","creating index...\n","index created!\n","\u001b[32m[03/16 08:51:26 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n","\u001b[32m[03/16 08:51:27 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.10 seconds.\n","\u001b[32m[03/16 08:51:27 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n","\u001b[32m[03/16 08:51:27 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.624\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.800\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.715\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.448\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.400\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.764\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.802\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.795\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.802\n","\u001b[32m[03/16 08:51:27 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n","|:------:|:------:|:------:|:-----:|:------:|:------:|\n","| 62.409 | 80.032 | 71.545 |  nan  | 44.799 | 62.662 |\n","\u001b[32m[03/16 08:51:27 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n","\u001b[32m[03/16 08:51:27 d2.engine.defaults]: \u001b[0mEvaluation results for beyond_words_val in csv format:\n","\u001b[32m[03/16 08:51:27 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n","\u001b[32m[03/16 08:51:27 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n","\u001b[32m[03/16 08:51:27 d2.evaluation.testing]: \u001b[0mcopypaste: 62.4089,80.0319,71.5450,nan,44.7993,62.6622\n","EPOCH 4\n","\u001b[32m[03/16 08:51:27 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n","    )\n","  )\n",")\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:51:27 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 08:51:27 d2.data.datasets.coco]: \u001b[0mLoaded 2575 images in COCO format from train_annos.json\n","\u001b[32m[03/16 08:51:27 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 2575 images left.\n","\u001b[32m[03/16 08:51:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","\u001b[32m[03/16 08:51:27 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[32m[03/16 08:51:27 d2.data.common]: \u001b[0mSerializing 2575 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 08:51:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.65 MiB\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:51:27 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n","\u001b[32m[03/16 08:51:28 d2.engine.hooks]: \u001b[0mLoading scheduler from state_dict ...\n","\u001b[32m[03/16 08:51:28 d2.engine.train_loop]: \u001b[0mStarting training from iteration 1376\n","\u001b[32m[03/16 08:51:28 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:00 (0:00:00 on hooks)\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:51:28 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 08:51:28 d2.data.datasets.coco]: \u001b[0mLoaded 644 images in COCO format from test_annos.json\n","\u001b[32m[03/16 08:51:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[03/16 08:51:28 d2.data.common]: \u001b[0mSerializing 644 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 08:51:28 d2.data.common]: \u001b[0mSerialized dataset takes 0.16 MiB\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:51:28 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n","\u001b[32m[03/16 08:51:28 d2.utils.events]: \u001b[0m iter: 1377    lr: N/A  max_mem: 751M\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:51:28 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:51:28 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 08:51:28 d2.data.datasets.coco]: \u001b[0mLoaded 644 images in COCO format from test_annos.json\n","\u001b[32m[03/16 08:51:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[03/16 08:51:28 d2.data.common]: \u001b[0mSerializing 644 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 08:51:28 d2.data.common]: \u001b[0mSerialized dataset takes 0.16 MiB\n","\u001b[32m[03/16 08:51:28 d2.evaluation.evaluator]: \u001b[0mStart inference on 644 batches\n","\u001b[32m[03/16 08:51:30 d2.evaluation.evaluator]: \u001b[0mInference done 14/644. Dataloading: 0.0013 s/iter. Inference: 0.1029 s/iter. Eval: 0.0002 s/iter. Total: 0.1044 s/iter. ETA=0:01:05\n","\u001b[32m[03/16 08:51:35 d2.evaluation.evaluator]: \u001b[0mInference done 61/644. Dataloading: 0.0021 s/iter. Inference: 0.1052 s/iter. Eval: 0.0002 s/iter. Total: 0.1078 s/iter. ETA=0:01:02\n","\u001b[32m[03/16 08:51:40 d2.evaluation.evaluator]: \u001b[0mInference done 108/644. Dataloading: 0.0019 s/iter. Inference: 0.1058 s/iter. Eval: 0.0002 s/iter. Total: 0.1081 s/iter. ETA=0:00:57\n","\u001b[32m[03/16 08:51:45 d2.evaluation.evaluator]: \u001b[0mInference done 155/644. Dataloading: 0.0019 s/iter. Inference: 0.1059 s/iter. Eval: 0.0002 s/iter. Total: 0.1081 s/iter. ETA=0:00:52\n","\u001b[32m[03/16 08:51:50 d2.evaluation.evaluator]: \u001b[0mInference done 201/644. Dataloading: 0.0021 s/iter. Inference: 0.1060 s/iter. Eval: 0.0002 s/iter. Total: 0.1084 s/iter. ETA=0:00:48\n","\u001b[32m[03/16 08:51:55 d2.evaluation.evaluator]: \u001b[0mInference done 248/644. Dataloading: 0.0021 s/iter. Inference: 0.1060 s/iter. Eval: 0.0002 s/iter. Total: 0.1085 s/iter. ETA=0:00:42\n","\u001b[32m[03/16 08:52:00 d2.evaluation.evaluator]: \u001b[0mInference done 295/644. Dataloading: 0.0020 s/iter. Inference: 0.1060 s/iter. Eval: 0.0002 s/iter. Total: 0.1084 s/iter. ETA=0:00:37\n","\u001b[32m[03/16 08:52:05 d2.evaluation.evaluator]: \u001b[0mInference done 341/644. Dataloading: 0.0020 s/iter. Inference: 0.1061 s/iter. Eval: 0.0002 s/iter. Total: 0.1085 s/iter. ETA=0:00:32\n","\u001b[32m[03/16 08:52:11 d2.evaluation.evaluator]: \u001b[0mInference done 388/644. Dataloading: 0.0020 s/iter. Inference: 0.1061 s/iter. Eval: 0.0002 s/iter. Total: 0.1085 s/iter. ETA=0:00:27\n","\u001b[32m[03/16 08:52:16 d2.evaluation.evaluator]: \u001b[0mInference done 434/644. Dataloading: 0.0020 s/iter. Inference: 0.1064 s/iter. Eval: 0.0002 s/iter. Total: 0.1087 s/iter. ETA=0:00:22\n","\u001b[32m[03/16 08:52:21 d2.evaluation.evaluator]: \u001b[0mInference done 480/644. Dataloading: 0.0019 s/iter. Inference: 0.1066 s/iter. Eval: 0.0002 s/iter. Total: 0.1088 s/iter. ETA=0:00:17\n","\u001b[32m[03/16 08:52:26 d2.evaluation.evaluator]: \u001b[0mInference done 527/644. Dataloading: 0.0019 s/iter. Inference: 0.1065 s/iter. Eval: 0.0002 s/iter. Total: 0.1088 s/iter. ETA=0:00:12\n","\u001b[32m[03/16 08:52:31 d2.evaluation.evaluator]: \u001b[0mInference done 567/644. Dataloading: 0.0027 s/iter. Inference: 0.1069 s/iter. Eval: 0.0002 s/iter. Total: 0.1099 s/iter. ETA=0:00:08\n","\u001b[32m[03/16 08:52:36 d2.evaluation.evaluator]: \u001b[0mInference done 595/644. Dataloading: 0.0057 s/iter. Inference: 0.1075 s/iter. Eval: 0.0002 s/iter. Total: 0.1136 s/iter. ETA=0:00:05\n","\u001b[32m[03/16 08:52:41 d2.evaluation.evaluator]: \u001b[0mInference done 623/644. Dataloading: 0.0081 s/iter. Inference: 0.1081 s/iter. Eval: 0.0002 s/iter. Total: 0.1166 s/iter. ETA=0:00:02\n","\u001b[32m[03/16 08:52:44 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:15.237497 (0.117743 s / iter per device, on 1 devices)\n","\u001b[32m[03/16 08:52:44 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:09 (0.108285 s / iter per device, on 1 devices)\n","\u001b[32m[03/16 08:52:44 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n","\u001b[32m[03/16 08:52:44 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ../model_weights/coco_instances_results.json\n","\u001b[32m[03/16 08:52:44 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n","Loading and preparing results...\n","DONE (t=0.18s)\n","creating index...\n","index created!\n","\u001b[32m[03/16 08:52:45 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n","\u001b[32m[03/16 08:52:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.09 seconds.\n","\u001b[32m[03/16 08:52:45 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n","\u001b[32m[03/16 08:52:45 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.624\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.800\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.715\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.448\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.400\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.764\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.802\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.795\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.802\n","\u001b[32m[03/16 08:52:45 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n","|:------:|:------:|:------:|:-----:|:------:|:------:|\n","| 62.409 | 80.032 | 71.545 |  nan  | 44.799 | 62.662 |\n","\u001b[32m[03/16 08:52:45 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n","\u001b[32m[03/16 08:52:45 d2.engine.defaults]: \u001b[0mEvaluation results for beyond_words_val in csv format:\n","\u001b[32m[03/16 08:52:45 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n","\u001b[32m[03/16 08:52:45 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n","\u001b[32m[03/16 08:52:45 d2.evaluation.testing]: \u001b[0mcopypaste: 62.4089,80.0319,71.5450,nan,44.7993,62.6622\n","EPOCH 5\n","\u001b[32m[03/16 08:52:45 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n","    )\n","  )\n",")\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:52:45 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 08:52:45 d2.data.datasets.coco]: \u001b[0mLoaded 2575 images in COCO format from train_annos.json\n","\u001b[32m[03/16 08:52:45 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 2575 images left.\n","\u001b[32m[03/16 08:52:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","\u001b[32m[03/16 08:52:46 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[32m[03/16 08:52:46 d2.data.common]: \u001b[0mSerializing 2575 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 08:52:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.65 MiB\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:52:46 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n","\u001b[32m[03/16 08:52:46 d2.engine.hooks]: \u001b[0mLoading scheduler from state_dict ...\n","\u001b[32m[03/16 08:52:46 d2.engine.train_loop]: \u001b[0mStarting training from iteration 1376\n","\u001b[32m[03/16 08:52:46 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:00 (0:00:00 on hooks)\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:52:46 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 08:52:46 d2.data.datasets.coco]: \u001b[0mLoaded 644 images in COCO format from test_annos.json\n","\u001b[32m[03/16 08:52:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[03/16 08:52:46 d2.data.common]: \u001b[0mSerializing 644 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 08:52:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.16 MiB\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:52:46 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n","\u001b[32m[03/16 08:52:46 d2.utils.events]: \u001b[0m iter: 1377    lr: N/A  max_mem: 751M\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:52:46 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:52:46 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 08:52:46 d2.data.datasets.coco]: \u001b[0mLoaded 644 images in COCO format from test_annos.json\n","\u001b[32m[03/16 08:52:46 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[03/16 08:52:46 d2.data.common]: \u001b[0mSerializing 644 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 08:52:46 d2.data.common]: \u001b[0mSerialized dataset takes 0.16 MiB\n","\u001b[32m[03/16 08:52:46 d2.evaluation.evaluator]: \u001b[0mStart inference on 644 batches\n","\u001b[32m[03/16 08:52:48 d2.evaluation.evaluator]: \u001b[0mInference done 11/644. Dataloading: 0.0013 s/iter. Inference: 0.1050 s/iter. Eval: 0.0002 s/iter. Total: 0.1066 s/iter. ETA=0:01:07\n","\u001b[32m[03/16 08:52:53 d2.evaluation.evaluator]: \u001b[0mInference done 57/644. Dataloading: 0.0017 s/iter. Inference: 0.1070 s/iter. Eval: 0.0002 s/iter. Total: 0.1091 s/iter. ETA=0:01:04\n","\u001b[32m[03/16 08:52:58 d2.evaluation.evaluator]: \u001b[0mInference done 103/644. Dataloading: 0.0017 s/iter. Inference: 0.1078 s/iter. Eval: 0.0002 s/iter. Total: 0.1098 s/iter. ETA=0:00:59\n","\u001b[32m[03/16 08:53:03 d2.evaluation.evaluator]: \u001b[0mInference done 149/644. Dataloading: 0.0018 s/iter. Inference: 0.1076 s/iter. Eval: 0.0002 s/iter. Total: 0.1097 s/iter. ETA=0:00:54\n","\u001b[32m[03/16 08:53:08 d2.evaluation.evaluator]: \u001b[0mInference done 195/644. Dataloading: 0.0018 s/iter. Inference: 0.1078 s/iter. Eval: 0.0002 s/iter. Total: 0.1099 s/iter. ETA=0:00:49\n","\u001b[32m[03/16 08:53:13 d2.evaluation.evaluator]: \u001b[0mInference done 241/644. Dataloading: 0.0019 s/iter. Inference: 0.1077 s/iter. Eval: 0.0002 s/iter. Total: 0.1099 s/iter. ETA=0:00:44\n","\u001b[32m[03/16 08:53:18 d2.evaluation.evaluator]: \u001b[0mInference done 287/644. Dataloading: 0.0018 s/iter. Inference: 0.1078 s/iter. Eval: 0.0002 s/iter. Total: 0.1100 s/iter. ETA=0:00:39\n","\u001b[32m[03/16 08:53:23 d2.evaluation.evaluator]: \u001b[0mInference done 333/644. Dataloading: 0.0018 s/iter. Inference: 0.1079 s/iter. Eval: 0.0002 s/iter. Total: 0.1100 s/iter. ETA=0:00:34\n","\u001b[32m[03/16 08:53:28 d2.evaluation.evaluator]: \u001b[0mInference done 379/644. Dataloading: 0.0018 s/iter. Inference: 0.1078 s/iter. Eval: 0.0002 s/iter. Total: 0.1100 s/iter. ETA=0:00:29\n","\u001b[32m[03/16 08:53:33 d2.evaluation.evaluator]: \u001b[0mInference done 425/644. Dataloading: 0.0018 s/iter. Inference: 0.1080 s/iter. Eval: 0.0002 s/iter. Total: 0.1101 s/iter. ETA=0:00:24\n","\u001b[32m[03/16 08:53:38 d2.evaluation.evaluator]: \u001b[0mInference done 470/644. Dataloading: 0.0018 s/iter. Inference: 0.1081 s/iter. Eval: 0.0002 s/iter. Total: 0.1102 s/iter. ETA=0:00:19\n","\u001b[32m[03/16 08:53:44 d2.evaluation.evaluator]: \u001b[0mInference done 516/644. Dataloading: 0.0018 s/iter. Inference: 0.1081 s/iter. Eval: 0.0002 s/iter. Total: 0.1102 s/iter. ETA=0:00:14\n","\u001b[32m[03/16 08:53:49 d2.evaluation.evaluator]: \u001b[0mInference done 560/644. Dataloading: 0.0021 s/iter. Inference: 0.1083 s/iter. Eval: 0.0002 s/iter. Total: 0.1107 s/iter. ETA=0:00:09\n","\u001b[32m[03/16 08:53:54 d2.evaluation.evaluator]: \u001b[0mInference done 589/644. Dataloading: 0.0047 s/iter. Inference: 0.1089 s/iter. Eval: 0.0002 s/iter. Total: 0.1139 s/iter. ETA=0:00:06\n","\u001b[32m[03/16 08:53:59 d2.evaluation.evaluator]: \u001b[0mInference done 615/644. Dataloading: 0.0074 s/iter. Inference: 0.1095 s/iter. Eval: 0.0002 s/iter. Total: 0.1172 s/iter. ETA=0:00:03\n","\u001b[32m[03/16 08:54:03 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:15.796225 (0.118617 s / iter per device, on 1 devices)\n","\u001b[32m[03/16 08:54:03 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:10 (0.109849 s / iter per device, on 1 devices)\n","\u001b[32m[03/16 08:54:03 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n","\u001b[32m[03/16 08:54:03 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ../model_weights/coco_instances_results.json\n","\u001b[32m[03/16 08:54:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n","Loading and preparing results...\n","DONE (t=0.01s)\n","creating index...\n","index created!\n","\u001b[32m[03/16 08:54:03 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n","\u001b[32m[03/16 08:54:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n","\u001b[32m[03/16 08:54:03 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n","\u001b[32m[03/16 08:54:03 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.624\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.800\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.715\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.448\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.400\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.764\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.802\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.795\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.802\n","\u001b[32m[03/16 08:54:03 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n","|:------:|:------:|:------:|:-----:|:------:|:------:|\n","| 62.409 | 80.032 | 71.545 |  nan  | 44.799 | 62.662 |\n","\u001b[32m[03/16 08:54:03 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n","\u001b[32m[03/16 08:54:03 d2.engine.defaults]: \u001b[0mEvaluation results for beyond_words_val in csv format:\n","\u001b[32m[03/16 08:54:03 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n","\u001b[32m[03/16 08:54:03 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n","\u001b[32m[03/16 08:54:03 d2.evaluation.testing]: \u001b[0mcopypaste: 62.4089,80.0319,71.5450,nan,44.7993,62.6622\n","EPOCH 6\n","\u001b[32m[03/16 08:54:04 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n","    )\n","  )\n",")\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:54:04 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 08:54:04 d2.data.datasets.coco]: \u001b[0mLoaded 2575 images in COCO format from train_annos.json\n","\u001b[32m[03/16 08:54:04 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 2575 images left.\n","\u001b[32m[03/16 08:54:04 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","\u001b[32m[03/16 08:54:04 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[32m[03/16 08:54:04 d2.data.common]: \u001b[0mSerializing 2575 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 08:54:04 d2.data.common]: \u001b[0mSerialized dataset takes 0.65 MiB\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:54:04 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n","\u001b[32m[03/16 08:54:05 d2.engine.hooks]: \u001b[0mLoading scheduler from state_dict ...\n","\u001b[32m[03/16 08:54:05 d2.engine.train_loop]: \u001b[0mStarting training from iteration 1376\n","\u001b[32m[03/16 08:54:05 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:00 (0:00:00 on hooks)\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:54:05 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 08:54:05 d2.data.datasets.coco]: \u001b[0mLoaded 644 images in COCO format from test_annos.json\n","\u001b[32m[03/16 08:54:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[03/16 08:54:05 d2.data.common]: \u001b[0mSerializing 644 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 08:54:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.16 MiB\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:54:05 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n","\u001b[32m[03/16 08:54:05 d2.utils.events]: \u001b[0m iter: 1377    lr: N/A  max_mem: 751M\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:54:05 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:54:05 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 08:54:05 d2.data.datasets.coco]: \u001b[0mLoaded 644 images in COCO format from test_annos.json\n","\u001b[32m[03/16 08:54:05 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[03/16 08:54:05 d2.data.common]: \u001b[0mSerializing 644 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 08:54:05 d2.data.common]: \u001b[0mSerialized dataset takes 0.16 MiB\n","\u001b[32m[03/16 08:54:05 d2.evaluation.evaluator]: \u001b[0mStart inference on 644 batches\n","\u001b[32m[03/16 08:54:06 d2.evaluation.evaluator]: \u001b[0mInference done 11/644. Dataloading: 0.0013 s/iter. Inference: 0.1066 s/iter. Eval: 0.0002 s/iter. Total: 0.1082 s/iter. ETA=0:01:08\n","\u001b[32m[03/16 08:54:11 d2.evaluation.evaluator]: \u001b[0mInference done 56/644. Dataloading: 0.0021 s/iter. Inference: 0.1085 s/iter. Eval: 0.0002 s/iter. Total: 0.1110 s/iter. ETA=0:01:05\n","\u001b[32m[03/16 08:54:16 d2.evaluation.evaluator]: \u001b[0mInference done 101/644. Dataloading: 0.0021 s/iter. Inference: 0.1093 s/iter. Eval: 0.0002 s/iter. Total: 0.1117 s/iter. ETA=0:01:00\n","\u001b[32m[03/16 08:54:21 d2.evaluation.evaluator]: \u001b[0mInference done 147/644. Dataloading: 0.0020 s/iter. Inference: 0.1089 s/iter. Eval: 0.0002 s/iter. Total: 0.1112 s/iter. ETA=0:00:55\n","\u001b[32m[03/16 08:54:27 d2.evaluation.evaluator]: \u001b[0mInference done 193/644. Dataloading: 0.0019 s/iter. Inference: 0.1088 s/iter. Eval: 0.0002 s/iter. Total: 0.1110 s/iter. ETA=0:00:50\n","\u001b[32m[03/16 08:54:32 d2.evaluation.evaluator]: \u001b[0mInference done 238/644. Dataloading: 0.0019 s/iter. Inference: 0.1089 s/iter. Eval: 0.0002 s/iter. Total: 0.1111 s/iter. ETA=0:00:45\n","\u001b[32m[03/16 08:54:37 d2.evaluation.evaluator]: \u001b[0mInference done 283/644. Dataloading: 0.0019 s/iter. Inference: 0.1089 s/iter. Eval: 0.0002 s/iter. Total: 0.1112 s/iter. ETA=0:00:40\n","\u001b[32m[03/16 08:54:42 d2.evaluation.evaluator]: \u001b[0mInference done 328/644. Dataloading: 0.0019 s/iter. Inference: 0.1089 s/iter. Eval: 0.0002 s/iter. Total: 0.1112 s/iter. ETA=0:00:35\n","\u001b[32m[03/16 08:54:47 d2.evaluation.evaluator]: \u001b[0mInference done 374/644. Dataloading: 0.0019 s/iter. Inference: 0.1088 s/iter. Eval: 0.0002 s/iter. Total: 0.1110 s/iter. ETA=0:00:29\n","\u001b[32m[03/16 08:54:52 d2.evaluation.evaluator]: \u001b[0mInference done 417/644. Dataloading: 0.0019 s/iter. Inference: 0.1094 s/iter. Eval: 0.0002 s/iter. Total: 0.1117 s/iter. ETA=0:00:25\n","\u001b[32m[03/16 08:54:57 d2.evaluation.evaluator]: \u001b[0mInference done 462/644. Dataloading: 0.0019 s/iter. Inference: 0.1095 s/iter. Eval: 0.0002 s/iter. Total: 0.1118 s/iter. ETA=0:00:20\n","\u001b[32m[03/16 08:55:02 d2.evaluation.evaluator]: \u001b[0mInference done 508/644. Dataloading: 0.0019 s/iter. Inference: 0.1094 s/iter. Eval: 0.0002 s/iter. Total: 0.1116 s/iter. ETA=0:00:15\n","\u001b[32m[03/16 08:55:07 d2.evaluation.evaluator]: \u001b[0mInference done 553/644. Dataloading: 0.0019 s/iter. Inference: 0.1094 s/iter. Eval: 0.0002 s/iter. Total: 0.1116 s/iter. ETA=0:00:10\n","\u001b[32m[03/16 08:55:12 d2.evaluation.evaluator]: \u001b[0mInference done 584/644. Dataloading: 0.0043 s/iter. Inference: 0.1100 s/iter. Eval: 0.0002 s/iter. Total: 0.1146 s/iter. ETA=0:00:06\n","\u001b[32m[03/16 08:55:17 d2.evaluation.evaluator]: \u001b[0mInference done 612/644. Dataloading: 0.0068 s/iter. Inference: 0.1106 s/iter. Eval: 0.0002 s/iter. Total: 0.1178 s/iter. ETA=0:00:03\n","\u001b[32m[03/16 08:55:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:16.558097 (0.119809 s / iter per device, on 1 devices)\n","\u001b[32m[03/16 08:55:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:10 (0.111032 s / iter per device, on 1 devices)\n","\u001b[32m[03/16 08:55:22 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n","\u001b[32m[03/16 08:55:22 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ../model_weights/coco_instances_results.json\n","\u001b[32m[03/16 08:55:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n","Loading and preparing results...\n","DONE (t=0.01s)\n","creating index...\n","index created!\n","\u001b[32m[03/16 08:55:22 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n","\u001b[32m[03/16 08:55:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.10 seconds.\n","\u001b[32m[03/16 08:55:22 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n","\u001b[32m[03/16 08:55:22 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.624\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.800\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.715\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.448\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.400\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.764\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.802\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.795\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.802\n","\u001b[32m[03/16 08:55:22 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n","|:------:|:------:|:------:|:-----:|:------:|:------:|\n","| 62.409 | 80.032 | 71.545 |  nan  | 44.799 | 62.662 |\n","\u001b[32m[03/16 08:55:22 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n","\u001b[32m[03/16 08:55:22 d2.engine.defaults]: \u001b[0mEvaluation results for beyond_words_val in csv format:\n","\u001b[32m[03/16 08:55:22 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n","\u001b[32m[03/16 08:55:22 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n","\u001b[32m[03/16 08:55:22 d2.evaluation.testing]: \u001b[0mcopypaste: 62.4089,80.0319,71.5450,nan,44.7993,62.6622\n","EPOCH 7\n","\u001b[32m[03/16 08:55:23 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n","    )\n","  )\n",")\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:55:23 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 08:55:23 d2.data.datasets.coco]: \u001b[0mLoaded 2575 images in COCO format from train_annos.json\n","\u001b[32m[03/16 08:55:23 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 2575 images left.\n","\u001b[32m[03/16 08:55:23 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","\u001b[32m[03/16 08:55:23 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[32m[03/16 08:55:23 d2.data.common]: \u001b[0mSerializing 2575 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 08:55:23 d2.data.common]: \u001b[0mSerialized dataset takes 0.65 MiB\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:55:23 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n","\u001b[32m[03/16 08:55:24 d2.engine.hooks]: \u001b[0mLoading scheduler from state_dict ...\n","\u001b[32m[03/16 08:55:24 d2.engine.train_loop]: \u001b[0mStarting training from iteration 1376\n","\u001b[32m[03/16 08:55:24 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:00 (0:00:00 on hooks)\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:55:24 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 08:55:24 d2.data.datasets.coco]: \u001b[0mLoaded 644 images in COCO format from test_annos.json\n","\u001b[32m[03/16 08:55:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[03/16 08:55:24 d2.data.common]: \u001b[0mSerializing 644 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 08:55:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.16 MiB\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:55:24 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n","\u001b[32m[03/16 08:55:24 d2.utils.events]: \u001b[0m iter: 1377    lr: N/A  max_mem: 751M\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:55:24 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:55:24 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 08:55:24 d2.data.datasets.coco]: \u001b[0mLoaded 644 images in COCO format from test_annos.json\n","\u001b[32m[03/16 08:55:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[03/16 08:55:24 d2.data.common]: \u001b[0mSerializing 644 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 08:55:24 d2.data.common]: \u001b[0mSerialized dataset takes 0.16 MiB\n","\u001b[32m[03/16 08:55:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 644 batches\n","\u001b[32m[03/16 08:55:26 d2.evaluation.evaluator]: \u001b[0mInference done 11/644. Dataloading: 0.0013 s/iter. Inference: 0.1078 s/iter. Eval: 0.0002 s/iter. Total: 0.1093 s/iter. ETA=0:01:09\n","\u001b[32m[03/16 08:55:31 d2.evaluation.evaluator]: \u001b[0mInference done 57/644. Dataloading: 0.0017 s/iter. Inference: 0.1079 s/iter. Eval: 0.0002 s/iter. Total: 0.1099 s/iter. ETA=0:01:04\n","\u001b[32m[03/16 08:55:36 d2.evaluation.evaluator]: \u001b[0mInference done 102/644. Dataloading: 0.0018 s/iter. Inference: 0.1086 s/iter. Eval: 0.0002 s/iter. Total: 0.1106 s/iter. ETA=0:00:59\n","\u001b[32m[03/16 08:55:41 d2.evaluation.evaluator]: \u001b[0mInference done 148/644. Dataloading: 0.0018 s/iter. Inference: 0.1083 s/iter. Eval: 0.0002 s/iter. Total: 0.1103 s/iter. ETA=0:00:54\n","\u001b[32m[03/16 08:55:46 d2.evaluation.evaluator]: \u001b[0mInference done 194/644. Dataloading: 0.0017 s/iter. Inference: 0.1084 s/iter. Eval: 0.0002 s/iter. Total: 0.1104 s/iter. ETA=0:00:49\n","\u001b[32m[03/16 08:55:51 d2.evaluation.evaluator]: \u001b[0mInference done 240/644. Dataloading: 0.0017 s/iter. Inference: 0.1085 s/iter. Eval: 0.0002 s/iter. Total: 0.1105 s/iter. ETA=0:00:44\n","\u001b[32m[03/16 08:55:56 d2.evaluation.evaluator]: \u001b[0mInference done 285/644. Dataloading: 0.0018 s/iter. Inference: 0.1086 s/iter. Eval: 0.0002 s/iter. Total: 0.1108 s/iter. ETA=0:00:39\n","\u001b[32m[03/16 08:56:01 d2.evaluation.evaluator]: \u001b[0mInference done 331/644. Dataloading: 0.0018 s/iter. Inference: 0.1087 s/iter. Eval: 0.0002 s/iter. Total: 0.1108 s/iter. ETA=0:00:34\n","\u001b[32m[03/16 08:56:06 d2.evaluation.evaluator]: \u001b[0mInference done 377/644. Dataloading: 0.0018 s/iter. Inference: 0.1086 s/iter. Eval: 0.0002 s/iter. Total: 0.1107 s/iter. ETA=0:00:29\n","\u001b[32m[03/16 08:56:11 d2.evaluation.evaluator]: \u001b[0mInference done 422/644. Dataloading: 0.0018 s/iter. Inference: 0.1087 s/iter. Eval: 0.0002 s/iter. Total: 0.1108 s/iter. ETA=0:00:24\n","\u001b[32m[03/16 08:56:16 d2.evaluation.evaluator]: \u001b[0mInference done 467/644. Dataloading: 0.0018 s/iter. Inference: 0.1089 s/iter. Eval: 0.0002 s/iter. Total: 0.1110 s/iter. ETA=0:00:19\n","\u001b[32m[03/16 08:56:21 d2.evaluation.evaluator]: \u001b[0mInference done 513/644. Dataloading: 0.0018 s/iter. Inference: 0.1087 s/iter. Eval: 0.0002 s/iter. Total: 0.1109 s/iter. ETA=0:00:14\n","\u001b[32m[03/16 08:56:26 d2.evaluation.evaluator]: \u001b[0mInference done 558/644. Dataloading: 0.0018 s/iter. Inference: 0.1089 s/iter. Eval: 0.0002 s/iter. Total: 0.1110 s/iter. ETA=0:00:09\n","\u001b[32m[03/16 08:56:32 d2.evaluation.evaluator]: \u001b[0mInference done 587/644. Dataloading: 0.0047 s/iter. Inference: 0.1094 s/iter. Eval: 0.0002 s/iter. Total: 0.1144 s/iter. ETA=0:00:06\n","\u001b[32m[03/16 08:56:37 d2.evaluation.evaluator]: \u001b[0mInference done 614/644. Dataloading: 0.0077 s/iter. Inference: 0.1099 s/iter. Eval: 0.0002 s/iter. Total: 0.1179 s/iter. ETA=0:00:03\n","\u001b[32m[03/16 08:56:41 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:16.303188 (0.119410 s / iter per device, on 1 devices)\n","\u001b[32m[03/16 08:56:41 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:10 (0.110256 s / iter per device, on 1 devices)\n","\u001b[32m[03/16 08:56:41 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n","\u001b[32m[03/16 08:56:41 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ../model_weights/coco_instances_results.json\n","\u001b[32m[03/16 08:56:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n","Loading and preparing results...\n","DONE (t=0.01s)\n","creating index...\n","index created!\n","\u001b[32m[03/16 08:56:41 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n","\u001b[32m[03/16 08:56:41 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.10 seconds.\n","\u001b[32m[03/16 08:56:41 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n","\u001b[32m[03/16 08:56:41 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.624\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.800\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.715\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.448\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.400\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.764\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.802\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.795\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.802\n","\u001b[32m[03/16 08:56:41 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n","|:------:|:------:|:------:|:-----:|:------:|:------:|\n","| 62.409 | 80.032 | 71.545 |  nan  | 44.799 | 62.662 |\n","\u001b[32m[03/16 08:56:41 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n","\u001b[32m[03/16 08:56:41 d2.engine.defaults]: \u001b[0mEvaluation results for beyond_words_val in csv format:\n","\u001b[32m[03/16 08:56:41 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n","\u001b[32m[03/16 08:56:41 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n","\u001b[32m[03/16 08:56:41 d2.evaluation.testing]: \u001b[0mcopypaste: 62.4089,80.0319,71.5450,nan,44.7993,62.6622\n","EPOCH 8\n","\u001b[32m[03/16 08:56:42 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n","    )\n","  )\n",")\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:56:42 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 08:56:42 d2.data.datasets.coco]: \u001b[0mLoaded 2575 images in COCO format from train_annos.json\n","\u001b[32m[03/16 08:56:42 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 2575 images left.\n","\u001b[32m[03/16 08:56:42 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","\u001b[32m[03/16 08:56:42 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[32m[03/16 08:56:42 d2.data.common]: \u001b[0mSerializing 2575 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 08:56:42 d2.data.common]: \u001b[0mSerialized dataset takes 0.65 MiB\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:56:42 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n","\u001b[32m[03/16 08:56:43 d2.engine.hooks]: \u001b[0mLoading scheduler from state_dict ...\n","\u001b[32m[03/16 08:56:43 d2.engine.train_loop]: \u001b[0mStarting training from iteration 1376\n","\u001b[32m[03/16 08:56:43 d2.engine.hooks]: \u001b[0mTotal training time: 0:00:00 (0:00:00 on hooks)\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:56:43 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 08:56:43 d2.data.datasets.coco]: \u001b[0mLoaded 644 images in COCO format from test_annos.json\n","\u001b[32m[03/16 08:56:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[03/16 08:56:43 d2.data.common]: \u001b[0mSerializing 644 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 08:56:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.16 MiB\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:56:43 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n","\u001b[32m[03/16 08:56:43 d2.utils.events]: \u001b[0m iter: 1377    lr: N/A  max_mem: 751M\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:56:43 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:56:43 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 08:56:43 d2.data.datasets.coco]: \u001b[0mLoaded 644 images in COCO format from test_annos.json\n","\u001b[32m[03/16 08:56:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[03/16 08:56:43 d2.data.common]: \u001b[0mSerializing 644 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 08:56:43 d2.data.common]: \u001b[0mSerialized dataset takes 0.16 MiB\n","\u001b[32m[03/16 08:56:43 d2.evaluation.evaluator]: \u001b[0mStart inference on 644 batches\n","\u001b[32m[03/16 08:56:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/644. Dataloading: 0.0014 s/iter. Inference: 0.1073 s/iter. Eval: 0.0002 s/iter. Total: 0.1089 s/iter. ETA=0:01:08\n","\u001b[32m[03/16 08:56:50 d2.evaluation.evaluator]: \u001b[0mInference done 56/644. Dataloading: 0.0018 s/iter. Inference: 0.1089 s/iter. Eval: 0.0002 s/iter. Total: 0.1110 s/iter. ETA=0:01:05\n","\u001b[32m[03/16 08:56:55 d2.evaluation.evaluator]: \u001b[0mInference done 101/644. Dataloading: 0.0018 s/iter. Inference: 0.1092 s/iter. Eval: 0.0002 s/iter. Total: 0.1112 s/iter. ETA=0:01:00\n","\u001b[32m[03/16 08:57:00 d2.evaluation.evaluator]: \u001b[0mInference done 147/644. Dataloading: 0.0018 s/iter. Inference: 0.1087 s/iter. Eval: 0.0002 s/iter. Total: 0.1107 s/iter. ETA=0:00:55\n","\u001b[32m[03/16 08:57:05 d2.evaluation.evaluator]: \u001b[0mInference done 193/644. Dataloading: 0.0017 s/iter. Inference: 0.1086 s/iter. Eval: 0.0002 s/iter. Total: 0.1106 s/iter. ETA=0:00:49\n","\u001b[32m[03/16 08:57:10 d2.evaluation.evaluator]: \u001b[0mInference done 238/644. Dataloading: 0.0018 s/iter. Inference: 0.1087 s/iter. Eval: 0.0002 s/iter. Total: 0.1108 s/iter. ETA=0:00:44\n","\u001b[32m[03/16 08:57:15 d2.evaluation.evaluator]: \u001b[0mInference done 283/644. Dataloading: 0.0018 s/iter. Inference: 0.1088 s/iter. Eval: 0.0002 s/iter. Total: 0.1109 s/iter. ETA=0:00:40\n","\u001b[32m[03/16 08:57:20 d2.evaluation.evaluator]: \u001b[0mInference done 329/644. Dataloading: 0.0018 s/iter. Inference: 0.1088 s/iter. Eval: 0.0002 s/iter. Total: 0.1109 s/iter. ETA=0:00:34\n","\u001b[32m[03/16 08:57:25 d2.evaluation.evaluator]: \u001b[0mInference done 375/644. Dataloading: 0.0017 s/iter. Inference: 0.1087 s/iter. Eval: 0.0002 s/iter. Total: 0.1108 s/iter. ETA=0:00:29\n","\u001b[32m[03/16 08:57:30 d2.evaluation.evaluator]: \u001b[0mInference done 420/644. Dataloading: 0.0018 s/iter. Inference: 0.1089 s/iter. Eval: 0.0002 s/iter. Total: 0.1109 s/iter. ETA=0:00:24\n","\u001b[32m[03/16 08:57:35 d2.evaluation.evaluator]: \u001b[0mInference done 465/644. Dataloading: 0.0018 s/iter. Inference: 0.1091 s/iter. Eval: 0.0002 s/iter. Total: 0.1111 s/iter. ETA=0:00:19\n","\u001b[32m[03/16 08:57:40 d2.evaluation.evaluator]: \u001b[0mInference done 511/644. Dataloading: 0.0018 s/iter. Inference: 0.1090 s/iter. Eval: 0.0002 s/iter. Total: 0.1111 s/iter. ETA=0:00:14\n","\u001b[32m[03/16 08:57:45 d2.evaluation.evaluator]: \u001b[0mInference done 556/644. Dataloading: 0.0018 s/iter. Inference: 0.1090 s/iter. Eval: 0.0002 s/iter. Total: 0.1111 s/iter. ETA=0:00:09\n","\u001b[32m[03/16 08:57:50 d2.evaluation.evaluator]: \u001b[0mInference done 585/644. Dataloading: 0.0045 s/iter. Inference: 0.1096 s/iter. Eval: 0.0002 s/iter. Total: 0.1143 s/iter. ETA=0:00:06\n","\u001b[32m[03/16 08:57:55 d2.evaluation.evaluator]: \u001b[0mInference done 613/644. Dataloading: 0.0070 s/iter. Inference: 0.1101 s/iter. Eval: 0.0002 s/iter. Total: 0.1175 s/iter. ETA=0:00:03\n","\u001b[32m[03/16 08:58:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:16.322589 (0.119441 s / iter per device, on 1 devices)\n","\u001b[32m[03/16 08:58:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:10 (0.110462 s / iter per device, on 1 devices)\n","\u001b[32m[03/16 08:58:00 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n","\u001b[32m[03/16 08:58:00 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ../model_weights/coco_instances_results.json\n","\u001b[32m[03/16 08:58:00 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n","Loading and preparing results...\n","DONE (t=0.01s)\n","creating index...\n","index created!\n","\u001b[32m[03/16 08:58:01 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n","\u001b[32m[03/16 08:58:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n","\u001b[32m[03/16 08:58:01 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n","\u001b[32m[03/16 08:58:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.624\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.800\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.715\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.448\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.627\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.400\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.764\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.802\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.795\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.802\n","\u001b[32m[03/16 08:58:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n","|:------:|:------:|:------:|:-----:|:------:|:------:|\n","| 62.409 | 80.032 | 71.545 |  nan  | 44.799 | 62.662 |\n","\u001b[32m[03/16 08:58:01 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n","\u001b[32m[03/16 08:58:01 d2.engine.defaults]: \u001b[0mEvaluation results for beyond_words_val in csv format:\n","\u001b[32m[03/16 08:58:01 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n","\u001b[32m[03/16 08:58:01 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n","\u001b[32m[03/16 08:58:01 d2.evaluation.testing]: \u001b[0mcopypaste: 62.4089,80.0319,71.5450,nan,44.7993,62.6622\n","EPOCH 9\n","\u001b[32m[03/16 08:58:01 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n","    )\n","  )\n",")\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:58:01 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 08:58:01 d2.data.datasets.coco]: \u001b[0mLoaded 2575 images in COCO format from train_annos.json\n","\u001b[32m[03/16 08:58:01 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 2575 images left.\n","\u001b[32m[03/16 08:58:01 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","\u001b[32m[03/16 08:58:01 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[32m[03/16 08:58:01 d2.data.common]: \u001b[0mSerializing 2575 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 08:58:01 d2.data.common]: \u001b[0mSerialized dataset takes 0.65 MiB\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 08:58:01 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n","\u001b[32m[03/16 08:58:02 d2.engine.hooks]: \u001b[0mLoading scheduler from state_dict ...\n","\u001b[32m[03/16 08:58:02 d2.engine.train_loop]: \u001b[0mStarting training from iteration 1376\n","\u001b[32m[03/16 08:58:13 d2.utils.events]: \u001b[0m eta: 0:06:49  iter: 1379  total_loss: 0.3138  loss_cls: 0.09388  loss_box_reg: 0.2149  loss_rpn_cls: 0.003873  loss_rpn_loc: 0.00724  time: 2.4349  data_time: 0.8523  lr: 0.00025  max_mem: 8153M\n","\u001b[32m[03/16 08:59:06 d2.utils.events]: \u001b[0m eta: 0:06:31  iter: 1399  total_loss: 0.3414  loss_cls: 0.1067  loss_box_reg: 0.2367  loss_rpn_cls: 0.002087  loss_rpn_loc: 0.00586  time: 2.6252  data_time: 0.6915  lr: 0.00025  max_mem: 9002M\n","\u001b[32m[03/16 08:59:57 d2.utils.events]: \u001b[0m eta: 0:05:30  iter: 1419  total_loss: 0.365  loss_cls: 0.1121  loss_box_reg: 0.2163  loss_rpn_cls: 0.001945  loss_rpn_loc: 0.004134  time: 2.5812  data_time: 0.6300  lr: 0.00025  max_mem: 9002M\n","\u001b[32m[03/16 09:00:47 d2.utils.events]: \u001b[0m eta: 0:04:33  iter: 1439  total_loss: 0.3431  loss_cls: 0.1115  loss_box_reg: 0.2397  loss_rpn_cls: 0.002881  loss_rpn_loc: 0.004704  time: 2.5668  data_time: 0.6298  lr: 0.00025  max_mem: 9002M\n","\u001b[32m[03/16 09:01:41 d2.utils.events]: \u001b[0m eta: 0:03:45  iter: 1459  total_loss: 0.316  loss_cls: 0.1054  loss_box_reg: 0.1977  loss_rpn_cls: 0.002871  loss_rpn_loc: 0.005385  time: 2.5925  data_time: 0.6576  lr: 0.00025  max_mem: 9215M\n","\u001b[32m[03/16 09:02:32 d2.utils.events]: \u001b[0m eta: 0:02:53  iter: 1479  total_loss: 0.2914  loss_cls: 0.1012  loss_box_reg: 0.1953  loss_rpn_cls: 0.001882  loss_rpn_loc: 0.005082  time: 2.5881  data_time: 0.6414  lr: 0.00025  max_mem: 9215M\n","\u001b[32m[03/16 09:03:24 d2.utils.events]: \u001b[0m eta: 0:02:02  iter: 1499  total_loss: 0.3181  loss_cls: 0.1001  loss_box_reg: 0.2102  loss_rpn_cls: 0.001197  loss_rpn_loc: 0.004331  time: 2.5884  data_time: 0.6532  lr: 0.00025  max_mem: 9215M\n","\u001b[32m[03/16 09:04:16 d2.utils.events]: \u001b[0m eta: 0:01:11  iter: 1519  total_loss: 0.3726  loss_cls: 0.111  loss_box_reg: 0.2367  loss_rpn_cls: 0.002248  loss_rpn_loc: 0.004717  time: 2.5917  data_time: 0.6868  lr: 0.00025  max_mem: 9215M\n","\u001b[32m[03/16 09:05:10 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 1539  total_loss: 0.3462  loss_cls: 0.1164  loss_box_reg: 0.225  loss_rpn_cls: 0.002568  loss_rpn_loc: 0.00523  time: 2.5994  data_time: 0.7234  lr: 0.00025  max_mem: 9215M\n","\u001b[32m[03/16 09:05:32 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1547  total_loss: 0.2986  loss_cls: 0.1076  loss_box_reg: 0.1814  loss_rpn_cls: 0.002699  loss_rpn_loc: 0.004897  time: 2.6043  data_time: 0.6931  lr: 0.00025  max_mem: 9215M\n","\u001b[32m[03/16 09:05:32 d2.engine.hooks]: \u001b[0mOverall training speed: 170 iterations in 0:07:22 (2.6043 s / it)\n","\u001b[32m[03/16 09:05:32 d2.engine.hooks]: \u001b[0mTotal training time: 0:07:24 (0:00:01 on hooks)\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 09:05:32 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 09:05:32 d2.data.datasets.coco]: \u001b[0mLoaded 644 images in COCO format from test_annos.json\n","\u001b[32m[03/16 09:05:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[03/16 09:05:33 d2.data.common]: \u001b[0mSerializing 644 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 09:05:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.16 MiB\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 09:05:33 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 09:05:33 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 09:05:33 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 09:05:33 d2.data.datasets.coco]: \u001b[0mLoaded 644 images in COCO format from test_annos.json\n","\u001b[32m[03/16 09:05:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[03/16 09:05:33 d2.data.common]: \u001b[0mSerializing 644 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 09:05:33 d2.data.common]: \u001b[0mSerialized dataset takes 0.16 MiB\n","\u001b[32m[03/16 09:05:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 644 batches\n","\u001b[32m[03/16 09:05:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/644. Dataloading: 0.0015 s/iter. Inference: 0.1068 s/iter. Eval: 0.0002 s/iter. Total: 0.1086 s/iter. ETA=0:01:08\n","\u001b[32m[03/16 09:05:39 d2.evaluation.evaluator]: \u001b[0mInference done 57/644. Dataloading: 0.0020 s/iter. Inference: 0.1075 s/iter. Eval: 0.0002 s/iter. Total: 0.1099 s/iter. ETA=0:01:04\n","\u001b[32m[03/16 09:05:44 d2.evaluation.evaluator]: \u001b[0mInference done 102/644. Dataloading: 0.0021 s/iter. Inference: 0.1091 s/iter. Eval: 0.0002 s/iter. Total: 0.1115 s/iter. ETA=0:01:00\n","\u001b[32m[03/16 09:05:49 d2.evaluation.evaluator]: \u001b[0mInference done 148/644. Dataloading: 0.0021 s/iter. Inference: 0.1085 s/iter. Eval: 0.0002 s/iter. Total: 0.1109 s/iter. ETA=0:00:55\n","\u001b[32m[03/16 09:05:54 d2.evaluation.evaluator]: \u001b[0mInference done 194/644. Dataloading: 0.0021 s/iter. Inference: 0.1084 s/iter. Eval: 0.0002 s/iter. Total: 0.1109 s/iter. ETA=0:00:49\n","\u001b[32m[03/16 09:06:00 d2.evaluation.evaluator]: \u001b[0mInference done 240/644. Dataloading: 0.0021 s/iter. Inference: 0.1082 s/iter. Eval: 0.0002 s/iter. Total: 0.1107 s/iter. ETA=0:00:44\n","\u001b[32m[03/16 09:06:05 d2.evaluation.evaluator]: \u001b[0mInference done 285/644. Dataloading: 0.0021 s/iter. Inference: 0.1084 s/iter. Eval: 0.0002 s/iter. Total: 0.1108 s/iter. ETA=0:00:39\n","\u001b[32m[03/16 09:06:10 d2.evaluation.evaluator]: \u001b[0mInference done 330/644. Dataloading: 0.0021 s/iter. Inference: 0.1084 s/iter. Eval: 0.0002 s/iter. Total: 0.1109 s/iter. ETA=0:00:34\n","\u001b[32m[03/16 09:06:15 d2.evaluation.evaluator]: \u001b[0mInference done 376/644. Dataloading: 0.0021 s/iter. Inference: 0.1083 s/iter. Eval: 0.0002 s/iter. Total: 0.1108 s/iter. ETA=0:00:29\n","\u001b[32m[03/16 09:06:20 d2.evaluation.evaluator]: \u001b[0mInference done 421/644. Dataloading: 0.0021 s/iter. Inference: 0.1084 s/iter. Eval: 0.0002 s/iter. Total: 0.1108 s/iter. ETA=0:00:24\n","\u001b[32m[03/16 09:06:25 d2.evaluation.evaluator]: \u001b[0mInference done 466/644. Dataloading: 0.0021 s/iter. Inference: 0.1087 s/iter. Eval: 0.0002 s/iter. Total: 0.1111 s/iter. ETA=0:00:19\n","\u001b[32m[03/16 09:06:30 d2.evaluation.evaluator]: \u001b[0mInference done 512/644. Dataloading: 0.0021 s/iter. Inference: 0.1086 s/iter. Eval: 0.0002 s/iter. Total: 0.1110 s/iter. ETA=0:00:14\n","\u001b[32m[03/16 09:06:35 d2.evaluation.evaluator]: \u001b[0mInference done 557/644. Dataloading: 0.0020 s/iter. Inference: 0.1087 s/iter. Eval: 0.0002 s/iter. Total: 0.1111 s/iter. ETA=0:00:09\n","\u001b[32m[03/16 09:06:40 d2.evaluation.evaluator]: \u001b[0mInference done 586/644. Dataloading: 0.0045 s/iter. Inference: 0.1094 s/iter. Eval: 0.0002 s/iter. Total: 0.1142 s/iter. ETA=0:00:06\n","\u001b[32m[03/16 09:06:45 d2.evaluation.evaluator]: \u001b[0mInference done 614/644. Dataloading: 0.0076 s/iter. Inference: 0.1099 s/iter. Eval: 0.0002 s/iter. Total: 0.1179 s/iter. ETA=0:00:03\n","\u001b[32m[03/16 09:06:50 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:16.282647 (0.119378 s / iter per device, on 1 devices)\n","\u001b[32m[03/16 09:06:50 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:10 (0.110318 s / iter per device, on 1 devices)\n","\u001b[32m[03/16 09:06:50 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n","\u001b[32m[03/16 09:06:50 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ../model_weights/coco_instances_results.json\n","\u001b[32m[03/16 09:06:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n","Loading and preparing results...\n","DONE (t=0.01s)\n","creating index...\n","index created!\n","\u001b[32m[03/16 09:06:50 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n","\u001b[32m[03/16 09:06:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.09 seconds.\n","\u001b[32m[03/16 09:06:50 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n","\u001b[32m[03/16 09:06:50 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.624\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.810\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.715\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.419\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.626\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.392\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.758\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.792\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.775\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.792\n","\u001b[32m[03/16 09:06:50 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n","|:------:|:------:|:------:|:-----:|:------:|:------:|\n","| 62.360 | 81.048 | 71.519 |  nan  | 41.950 | 62.603 |\n","\u001b[32m[03/16 09:06:50 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n","\u001b[32m[03/16 09:06:50 d2.engine.defaults]: \u001b[0mEvaluation results for beyond_words_val in csv format:\n","\u001b[32m[03/16 09:06:50 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n","\u001b[32m[03/16 09:06:50 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n","\u001b[32m[03/16 09:06:50 d2.evaluation.testing]: \u001b[0mcopypaste: 62.3603,81.0481,71.5189,nan,41.9499,62.6035\n","EPOCH 10\n","\u001b[32m[03/16 09:06:51 d2.engine.defaults]: \u001b[0mModel:\n","GeneralizedRCNN(\n","  (backbone): FPN(\n","    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n","    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (top_block): LastLevelMaxPool()\n","    (bottom_up): ResNet(\n","      (stem): BasicStem(\n","        (conv1): Conv2d(\n","          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n","          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","        )\n","      )\n","      (res2): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res3): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res4): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (3): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (4): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","        (5): BottleneckBlock(\n","          (conv1): Conv2d(\n","            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n","          )\n","        )\n","      )\n","      (res5): Sequential(\n","        (0): BottleneckBlock(\n","          (shortcut): Conv2d(\n","            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","          (conv1): Conv2d(\n","            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (1): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","        (2): BottleneckBlock(\n","          (conv1): Conv2d(\n","            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv2): Conv2d(\n","            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n","          )\n","          (conv3): Conv2d(\n","            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n","            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (proposal_generator): RPN(\n","    (rpn_head): StandardRPNHead(\n","      (conv): Conv2d(\n","        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n","        (activation): ReLU()\n","      )\n","      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n","      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n","    )\n","    (anchor_generator): DefaultAnchorGenerator(\n","      (cell_anchors): BufferList()\n","    )\n","  )\n","  (roi_heads): StandardROIHeads(\n","    (box_pooler): ROIPooler(\n","      (level_poolers): ModuleList(\n","        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n","        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n","        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n","        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n","      )\n","    )\n","    (box_head): FastRCNNConvFCHead(\n","      (flatten): Flatten(start_dim=1, end_dim=-1)\n","      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n","      (fc_relu1): ReLU()\n","      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n","      (fc_relu2): ReLU()\n","    )\n","    (box_predictor): FastRCNNOutputLayers(\n","      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n","      (bbox_pred): Linear(in_features=1024, out_features=4, bias=True)\n","    )\n","  )\n",")\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 09:06:51 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 09:06:51 d2.data.datasets.coco]: \u001b[0mLoaded 2575 images in COCO format from train_annos.json\n","\u001b[32m[03/16 09:06:51 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 2575 images left.\n","\u001b[32m[03/16 09:06:51 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n","\u001b[32m[03/16 09:06:51 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n","\u001b[32m[03/16 09:06:51 d2.data.common]: \u001b[0mSerializing 2575 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 09:06:51 d2.data.common]: \u001b[0mSerialized dataset takes 0.65 MiB\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 09:06:51 d2.solver.build]: \u001b[0mSOLVER.STEPS contains values larger than SOLVER.MAX_ITER. These values will be ignored.\n","\u001b[32m[03/16 09:06:52 d2.engine.hooks]: \u001b[0mLoading scheduler from state_dict ...\n","\u001b[32m[03/16 09:06:52 d2.engine.train_loop]: \u001b[0mStarting training from iteration 1548\n","\u001b[32m[03/16 09:07:21 d2.utils.events]: \u001b[0m eta: 0:06:15  iter: 1559  total_loss: 0.353  loss_cls: 0.1066  loss_box_reg: 0.2294  loss_rpn_cls: 0.001984  loss_rpn_loc: 0.005039  time: 2.3827  data_time: 0.5025  lr: 0.00025  max_mem: 9215M\n","\u001b[32m[03/16 09:08:08 d2.utils.events]: \u001b[0m eta: 0:05:33  iter: 1579  total_loss: 0.333  loss_cls: 0.1  loss_box_reg: 0.2311  loss_rpn_cls: 0.001849  loss_rpn_loc: 0.006454  time: 2.3776  data_time: 0.4799  lr: 0.00025  max_mem: 9215M\n","\u001b[32m[03/16 09:08:59 d2.utils.events]: \u001b[0m eta: 0:04:50  iter: 1599  total_loss: 0.3352  loss_cls: 0.118  loss_box_reg: 0.2093  loss_rpn_cls: 0.003039  loss_rpn_loc: 0.006508  time: 2.4413  data_time: 0.5876  lr: 0.00025  max_mem: 9215M\n","\u001b[32m[03/16 09:09:49 d2.utils.events]: \u001b[0m eta: 0:04:03  iter: 1619  total_loss: 0.3517  loss_cls: 0.09448  loss_box_reg: 0.238  loss_rpn_cls: 0.001568  loss_rpn_loc: 0.005035  time: 2.4504  data_time: 0.4954  lr: 0.00025  max_mem: 9215M\n","\u001b[32m[03/16 09:10:37 d2.utils.events]: \u001b[0m eta: 0:03:13  iter: 1639  total_loss: 0.337  loss_cls: 0.1076  loss_box_reg: 0.2187  loss_rpn_cls: 0.002272  loss_rpn_loc: 0.005596  time: 2.4402  data_time: 0.5094  lr: 0.00025  max_mem: 9215M\n","\u001b[32m[03/16 09:11:27 d2.utils.events]: \u001b[0m eta: 0:02:25  iter: 1659  total_loss: 0.3146  loss_cls: 0.1099  loss_box_reg: 0.2048  loss_rpn_cls: 0.002071  loss_rpn_loc: 0.00438  time: 2.4518  data_time: 0.5293  lr: 0.00025  max_mem: 9215M\n","\u001b[32m[03/16 09:12:17 d2.utils.events]: \u001b[0m eta: 0:01:37  iter: 1679  total_loss: 0.3535  loss_cls: 0.09727  loss_box_reg: 0.2198  loss_rpn_cls: 0.002122  loss_rpn_loc: 0.005051  time: 2.4569  data_time: 0.5132  lr: 0.00025  max_mem: 9215M\n","\u001b[32m[03/16 09:13:08 d2.utils.events]: \u001b[0m eta: 0:00:48  iter: 1699  total_loss: 0.3233  loss_cls: 0.1058  loss_box_reg: 0.2017  loss_rpn_cls: 0.002643  loss_rpn_loc: 0.004588  time: 2.4718  data_time: 0.5487  lr: 0.00025  max_mem: 9415M\n","\u001b[32m[03/16 09:13:59 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1719  total_loss: 0.3209  loss_cls: 0.1007  loss_box_reg: 0.2132  loss_rpn_cls: 0.002512  loss_rpn_loc: 0.006961  time: 2.4721  data_time: 0.5397  lr: 0.00025  max_mem: 9415M\n","\u001b[32m[03/16 09:13:59 d2.engine.hooks]: \u001b[0mOverall training speed: 170 iterations in 0:07:00 (2.4721 s / it)\n","\u001b[32m[03/16 09:13:59 d2.engine.hooks]: \u001b[0mTotal training time: 0:07:01 (0:00:01 on hooks)\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 09:13:59 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 09:13:59 d2.data.datasets.coco]: \u001b[0mLoaded 644 images in COCO format from test_annos.json\n","\u001b[32m[03/16 09:13:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[03/16 09:13:59 d2.data.common]: \u001b[0mSerializing 644 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 09:13:59 d2.data.common]: \u001b[0mSerialized dataset takes 0.16 MiB\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 09:13:59 d2.engine.defaults]: \u001b[0mNo evaluator found. Use `DefaultTrainer.test(evaluators=)`, or implement its `build_evaluator` method.\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 09:13:59 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n","\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[03/16 09:13:59 d2.data.datasets.coco]: \u001b[0m\n","Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n","\n","\u001b[32m[03/16 09:13:59 d2.data.datasets.coco]: \u001b[0mLoaded 644 images in COCO format from test_annos.json\n","\u001b[32m[03/16 09:13:59 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n","\u001b[32m[03/16 09:13:59 d2.data.common]: \u001b[0mSerializing 644 elements to byte tensors and concatenating them all ...\n","\u001b[32m[03/16 09:13:59 d2.data.common]: \u001b[0mSerialized dataset takes 0.16 MiB\n","\u001b[32m[03/16 09:13:59 d2.evaluation.evaluator]: \u001b[0mStart inference on 644 batches\n","\u001b[32m[03/16 09:14:00 d2.evaluation.evaluator]: \u001b[0mInference done 11/644. Dataloading: 0.0013 s/iter. Inference: 0.1076 s/iter. Eval: 0.0002 s/iter. Total: 0.1091 s/iter. ETA=0:01:09\n","\u001b[32m[03/16 09:14:05 d2.evaluation.evaluator]: \u001b[0mInference done 57/644. Dataloading: 0.0019 s/iter. Inference: 0.1082 s/iter. Eval: 0.0002 s/iter. Total: 0.1104 s/iter. ETA=0:01:04\n","\u001b[32m[03/16 09:14:10 d2.evaluation.evaluator]: \u001b[0mInference done 101/644. Dataloading: 0.0021 s/iter. Inference: 0.1096 s/iter. Eval: 0.0003 s/iter. Total: 0.1121 s/iter. ETA=0:01:00\n","\u001b[32m[03/16 09:14:15 d2.evaluation.evaluator]: \u001b[0mInference done 147/644. Dataloading: 0.0021 s/iter. Inference: 0.1090 s/iter. Eval: 0.0002 s/iter. Total: 0.1114 s/iter. ETA=0:00:55\n","\u001b[32m[03/16 09:14:21 d2.evaluation.evaluator]: \u001b[0mInference done 193/644. Dataloading: 0.0020 s/iter. Inference: 0.1088 s/iter. Eval: 0.0002 s/iter. Total: 0.1112 s/iter. ETA=0:00:50\n","\u001b[32m[03/16 09:14:26 d2.evaluation.evaluator]: \u001b[0mInference done 239/644. Dataloading: 0.0020 s/iter. Inference: 0.1088 s/iter. Eval: 0.0002 s/iter. Total: 0.1111 s/iter. ETA=0:00:45\n","\u001b[32m[03/16 09:14:31 d2.evaluation.evaluator]: \u001b[0mInference done 284/644. Dataloading: 0.0019 s/iter. Inference: 0.1089 s/iter. Eval: 0.0002 s/iter. Total: 0.1112 s/iter. ETA=0:00:40\n","\u001b[32m[03/16 09:14:36 d2.evaluation.evaluator]: \u001b[0mInference done 330/644. Dataloading: 0.0019 s/iter. Inference: 0.1089 s/iter. Eval: 0.0002 s/iter. Total: 0.1112 s/iter. ETA=0:00:34\n","\u001b[32m[03/16 09:14:41 d2.evaluation.evaluator]: \u001b[0mInference done 376/644. Dataloading: 0.0019 s/iter. Inference: 0.1088 s/iter. Eval: 0.0002 s/iter. Total: 0.1110 s/iter. ETA=0:00:29\n","\u001b[32m[03/16 09:14:46 d2.evaluation.evaluator]: \u001b[0mInference done 421/644. Dataloading: 0.0018 s/iter. Inference: 0.1088 s/iter. Eval: 0.0002 s/iter. Total: 0.1110 s/iter. ETA=0:00:24\n","\u001b[32m[03/16 09:14:51 d2.evaluation.evaluator]: \u001b[0mInference done 466/644. Dataloading: 0.0018 s/iter. Inference: 0.1090 s/iter. Eval: 0.0002 s/iter. Total: 0.1112 s/iter. ETA=0:00:19\n","\u001b[32m[03/16 09:14:56 d2.evaluation.evaluator]: \u001b[0mInference done 512/644. Dataloading: 0.0018 s/iter. Inference: 0.1088 s/iter. Eval: 0.0002 s/iter. Total: 0.1110 s/iter. ETA=0:00:14\n","\u001b[32m[03/16 09:15:01 d2.evaluation.evaluator]: \u001b[0mInference done 557/644. Dataloading: 0.0018 s/iter. Inference: 0.1089 s/iter. Eval: 0.0002 s/iter. Total: 0.1111 s/iter. ETA=0:00:09\n","\u001b[32m[03/16 09:15:06 d2.evaluation.evaluator]: \u001b[0mInference done 586/644. Dataloading: 0.0045 s/iter. Inference: 0.1094 s/iter. Eval: 0.0002 s/iter. Total: 0.1143 s/iter. ETA=0:00:06\n","\u001b[32m[03/16 09:15:11 d2.evaluation.evaluator]: \u001b[0mInference done 613/644. Dataloading: 0.0070 s/iter. Inference: 0.1100 s/iter. Eval: 0.0002 s/iter. Total: 0.1174 s/iter. ETA=0:00:03\n","\u001b[32m[03/16 09:15:16 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:16.228884 (0.119294 s / iter per device, on 1 devices)\n","\u001b[32m[03/16 09:15:16 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:10 (0.110366 s / iter per device, on 1 devices)\n","\u001b[32m[03/16 09:15:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n","\u001b[32m[03/16 09:15:16 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ../model_weights/coco_instances_results.json\n","\u001b[32m[03/16 09:15:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n","Loading and preparing results...\n","DONE (t=0.01s)\n","creating index...\n","index created!\n","\u001b[32m[03/16 09:15:16 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n","\u001b[32m[03/16 09:15:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.08 seconds.\n","\u001b[32m[03/16 09:15:16 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n","\u001b[32m[03/16 09:15:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.02 seconds.\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.641\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.813\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.733\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.465\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.644\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.402\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.776\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.809\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.785\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.809\n","\u001b[32m[03/16 09:15:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n","|   AP   |  AP50  |  AP75  |  APs  |  APm   |  APl   |\n","|:------:|:------:|:------:|:-----:|:------:|:------:|\n","| 64.078 | 81.348 | 73.256 |  nan  | 46.535 | 64.366 |\n","\u001b[32m[03/16 09:15:16 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n","\u001b[32m[03/16 09:15:16 d2.engine.defaults]: \u001b[0mEvaluation results for beyond_words_val in csv format:\n","\u001b[32m[03/16 09:15:16 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n","\u001b[32m[03/16 09:15:16 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n","\u001b[32m[03/16 09:15:16 d2.evaluation.testing]: \u001b[0mcopypaste: 64.0779,81.3483,73.2562,nan,46.5349,64.3663\n"]}],"source":["print(\"EPOCH 1\")\n","\n","\n","# trains for one epoch\n","trainer = DefaultTrainer(cfg) \n","trainer.resume_or_load(resume=True)  #change here if resuming\n","trainer.train()\n","\n","######## FOR SAVING MODEL WEIGHTS AFTER EACH EPOCH TO AN S3 BUCKET #########\n","# with open(\"../model_weights/model_final.pth\", \"rb\") as f:\n","#     s3.upload_fileobj(f, \"BUCKET-NAME-HERE\", \"new_val_model_weights/model_epoch_1.pth\")\n","############################################################################\n","\n","# evaluates on validation data after one epoch\n","# metrics are printed out to console\n","trainer.test(trainer.cfg, trainer.model, COCOEvaluator(\"beyond_words_val\", trainer.cfg, False, trainer.cfg.OUTPUT_DIR))\n","\n","######## FOR SAVING PREDICTIONS ON VALIDATION SET AFTER EACH EPOCH TO AN S3 BUCKET ########\n","# with open(\"../model_weights/coco_instances_results.json\", \"rb\") as f:\n","#     s3.upload_fileobj(f, \"BUCKET-NAME-HERE\", \"new_val_model_weights/coco_results_epoch_1.json\")\n","###########################################################################################\n","\n","# trains then evaluates on validation data iteratively for desired number of epochs\n","for i in range(0, epoch_num-1):\n","    \n","    print(\"EPOCH \" + str(i+2))\n","\n","    # trains again\n","    cfg.SOLVER.MAX_ITER = epoch*(i+2)\n","    trainer = DefaultTrainer(cfg) \n","    trainer.resume_or_load(resume=True)\n","    trainer.train()\n","    \n","    ######## FOR SAVING MODEL WEIGHTS AFTER EACH EPOCH TO AN S3 BUCKET #########\n","#     with open(\"../model_weights/model_final.pth\", \"rb\") as f:\n","#         s3.upload_fileobj(f, \"BUCKET-NAME-HERE\", \"new_val_model_weights/model_eopch_\" + str(i+2) + \".pth\")\n","    ############################################################################   \n","    \n","    trainer.test(trainer.cfg, trainer.model, COCOEvaluator(\"beyond_words_val\", trainer.cfg, False, trainer.cfg.OUTPUT_DIR))\n","\n","    ######## FOR SAVING PREDICTIONS ON VALIDATION SET AFTER EACH EPOCH TO AN S3 BUCKET ########\n","#     with open(\"../model_weights/coco_instances_results.json\", \"rb\") as f:\n","#         s3.upload_fileobj(f, \"BUCKET-NAME-HERE\", \"new_val_model_weights/coco_results_epoch_\" + str(i+2) + \".json\")\n","    ###########################################################################################"]},{"cell_type":"markdown","metadata":{"id":"Mcs9pax-GNKI"},"source":["# Next, we create a predictor for predicting on examples from the validaton set.\n","\n","This cell generates a predictor for performing predictions on the validation examples:"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"BbjWkFt3XDcg","executionInfo":{"status":"ok","timestamp":1647422621118,"user_tz":-60,"elapsed":1338,"user":{"displayName":"Elisa Michelet","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17163883302948708095"}}},"outputs":[],"source":["# sets the testing confidence threshold\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5\n","cfg.DATASETS.TEST = (\"beyond_words_val\", )\n","\n","cfg.merge_from_file(\"../..//detectron2/configs/COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n","cfg.MODEL.WEIGHTS = \"../model_weights/model_final.pth\"\n","\n","predictor = DefaultPredictor(cfg)"]},{"cell_type":"markdown","metadata":{"id":"es_OlnYvGWDG"},"source":["# Lastly, we display the predictions.\n","\n","This cell shows some sample predictions in the notebook itself:"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1hBuef7E79MvyT4me3wwyj2vJLqur7csj"},"id":"-DO7Cu5HN8q5","outputId":"a5b5a55d-330c-4bb0-f644-e7cc5926fbcd","scrolled":false,"executionInfo":{"status":"ok","timestamp":1647423754105,"user_tz":-60,"elapsed":25367,"user":{"displayName":"Elisa Michelet","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17163883302948708095"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["n_test_to_display = 20\n","\n","for d in random.sample(DatasetCatalog.get(\"beyond_words_val\"), n_test_to_display):    \n","    im = cv2.imread(d[\"file_name\"])\n","    outputs = predictor(im)\n","    v = Visualizer(im[:, :, ::-1],\n","                   metadata=MetadataCatalog.get(\"beyond_words_val\"), \n","                   scale=1.2   )\n","    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","    #v = v.draw_dataset_dict(d)\n","    plt.figure(figsize=(15,12))\n","    plt.imshow(v.get_image()[:, :, ::-1])\n","    \n","    # if we want to save the images:\n","    # cv2.imwrite(filepath_here, v.get_image()[:, :, ::-1])\n"]},{"cell_type":"code","source":[""],"metadata":{"id":"v5sLlFeeAvjK"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"train_model_dfkv.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":0}